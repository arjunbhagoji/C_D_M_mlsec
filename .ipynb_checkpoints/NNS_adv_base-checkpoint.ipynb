{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 784)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_in_train=X_train.reshape(50000,784)\n",
    "PCA_in_val=X_val.reshape(10000,784)\n",
    "PCA_in_test=X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing PCA over the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train=pca.fit(PCA_in_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PCA_out_train=PCA(PCA_in_train,standardize=False)\n",
    "\n",
    "var_sum=0\n",
    "for i in range(784):\n",
    "    var_sum=var_sum+PCA_out.fracs[i]\n",
    "    if var_sum>0.99:\n",
    "        print(\"{}\".format(i))\n",
    "        break\n",
    "\n",
    "rd=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dr=pca.transform(PCA_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rd=X_train_dr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dr=X_train_dr.reshape((50000,1,rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_dr=pca.transform(PCA_in_test).reshape((10000,1,rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_dr=pca.transform(PCA_in_val).reshape((10000,1,rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network learning with DR examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from lasagne.regularization import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # By default, this creates the same network as `build_mlp`, but it can be\n",
    "    # customized with respect to the number and size of hidden layers. This\n",
    "    # mostly showcases how creating a network in Python code can be a lot more\n",
    "    # flexible than a configuration file. Note that to make the code easier,\n",
    "    # all the layers are just called `network` -- there is no need to give them\n",
    "    # different names if all we return is the last one we created anyway; we\n",
    "    # just used different names above for clarity.\n",
    "\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, rd),\n",
    "                                        input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 1.007s\n",
      "  training loss:\t\t2.023481\n",
      "  validation loss:\t\t0.934638\n",
      "  validation accuracy:\t\t85.32 %\n",
      "Epoch 2 of 500 took 1.118s\n",
      "  training loss:\t\t1.342471\n",
      "  validation loss:\t\t0.929364\n",
      "  validation accuracy:\t\t85.64 %\n",
      "Epoch 3 of 500 took 1.077s\n",
      "  training loss:\t\t1.337830\n",
      "  validation loss:\t\t0.930277\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 4 of 500 took 0.949s\n",
      "  training loss:\t\t1.337398\n",
      "  validation loss:\t\t0.926665\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 5 of 500 took 0.966s\n",
      "  training loss:\t\t1.337342\n",
      "  validation loss:\t\t0.928611\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 6 of 500 took 0.882s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.928754\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 7 of 500 took 1.347s\n",
      "  training loss:\t\t1.337315\n",
      "  validation loss:\t\t0.927960\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 8 of 500 took 1.279s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.926996\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 9 of 500 took 0.987s\n",
      "  training loss:\t\t1.337322\n",
      "  validation loss:\t\t0.928013\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 10 of 500 took 0.958s\n",
      "  training loss:\t\t1.337202\n",
      "  validation loss:\t\t0.927216\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 11 of 500 took 0.969s\n",
      "  training loss:\t\t1.337234\n",
      "  validation loss:\t\t0.928673\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 12 of 500 took 1.331s\n",
      "  training loss:\t\t1.337178\n",
      "  validation loss:\t\t0.926698\n",
      "  validation accuracy:\t\t85.88 %\n",
      "Epoch 13 of 500 took 0.921s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.927236\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 14 of 500 took 1.106s\n",
      "  training loss:\t\t1.337263\n",
      "  validation loss:\t\t0.927301\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 15 of 500 took 1.382s\n",
      "  training loss:\t\t1.337166\n",
      "  validation loss:\t\t0.925892\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 16 of 500 took 0.942s\n",
      "  training loss:\t\t1.337180\n",
      "  validation loss:\t\t0.927091\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 17 of 500 took 1.001s\n",
      "  training loss:\t\t1.337232\n",
      "  validation loss:\t\t0.927187\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 18 of 500 took 1.040s\n",
      "  training loss:\t\t1.337315\n",
      "  validation loss:\t\t0.927154\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 19 of 500 took 0.988s\n",
      "  training loss:\t\t1.337201\n",
      "  validation loss:\t\t0.926472\n",
      "  validation accuracy:\t\t85.82 %\n",
      "Epoch 20 of 500 took 1.151s\n",
      "  training loss:\t\t1.337235\n",
      "  validation loss:\t\t0.925924\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 21 of 500 took 0.945s\n",
      "  training loss:\t\t1.337175\n",
      "  validation loss:\t\t0.926323\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 22 of 500 took 1.006s\n",
      "  training loss:\t\t1.337258\n",
      "  validation loss:\t\t0.927807\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 23 of 500 took 1.140s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.926184\n",
      "  validation accuracy:\t\t85.84 %\n",
      "Epoch 24 of 500 took 0.943s\n",
      "  training loss:\t\t1.337241\n",
      "  validation loss:\t\t0.926770\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 25 of 500 took 0.969s\n",
      "  training loss:\t\t1.337245\n",
      "  validation loss:\t\t0.927367\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 26 of 500 took 1.016s\n",
      "  training loss:\t\t1.337278\n",
      "  validation loss:\t\t0.926418\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 27 of 500 took 1.385s\n",
      "  training loss:\t\t1.337263\n",
      "  validation loss:\t\t0.926412\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 28 of 500 took 0.955s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.925203\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 29 of 500 took 0.973s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.927794\n",
      "  validation accuracy:\t\t85.86 %\n",
      "Epoch 30 of 500 took 0.994s\n",
      "  training loss:\t\t1.337177\n",
      "  validation loss:\t\t0.927398\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 31 of 500 took 0.953s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.926193\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 32 of 500 took 0.963s\n",
      "  training loss:\t\t1.337359\n",
      "  validation loss:\t\t0.926578\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 33 of 500 took 1.153s\n",
      "  training loss:\t\t1.337268\n",
      "  validation loss:\t\t0.926693\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 34 of 500 took 0.912s\n",
      "  training loss:\t\t1.337320\n",
      "  validation loss:\t\t0.926456\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 35 of 500 took 1.027s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.927144\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 36 of 500 took 1.106s\n",
      "  training loss:\t\t1.337275\n",
      "  validation loss:\t\t0.926431\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 37 of 500 took 1.029s\n",
      "  training loss:\t\t1.337252\n",
      "  validation loss:\t\t0.928605\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 38 of 500 took 0.977s\n",
      "  training loss:\t\t1.337267\n",
      "  validation loss:\t\t0.927881\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 39 of 500 took 0.921s\n",
      "  training loss:\t\t1.337269\n",
      "  validation loss:\t\t0.926310\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 40 of 500 took 1.265s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.928233\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 41 of 500 took 0.942s\n",
      "  training loss:\t\t1.337206\n",
      "  validation loss:\t\t0.926527\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 42 of 500 took 1.376s\n",
      "  training loss:\t\t1.337197\n",
      "  validation loss:\t\t0.926807\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 43 of 500 took 1.524s\n",
      "  training loss:\t\t1.337205\n",
      "  validation loss:\t\t0.926447\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 44 of 500 took 1.244s\n",
      "  training loss:\t\t1.337203\n",
      "  validation loss:\t\t0.926524\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 45 of 500 took 1.621s\n",
      "  training loss:\t\t1.337302\n",
      "  validation loss:\t\t0.926821\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 46 of 500 took 1.041s\n",
      "  training loss:\t\t1.337172\n",
      "  validation loss:\t\t0.926456\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 47 of 500 took 0.955s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.927434\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 48 of 500 took 0.831s\n",
      "  training loss:\t\t1.337250\n",
      "  validation loss:\t\t0.925895\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 49 of 500 took 0.814s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.927675\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 50 of 500 took 0.944s\n",
      "  training loss:\t\t1.337242\n",
      "  validation loss:\t\t0.926583\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 51 of 500 took 0.814s\n",
      "  training loss:\t\t1.337198\n",
      "  validation loss:\t\t0.927192\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 52 of 500 took 0.824s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.926073\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 53 of 500 took 0.855s\n",
      "  training loss:\t\t1.337253\n",
      "  validation loss:\t\t0.927532\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 54 of 500 took 0.829s\n",
      "  training loss:\t\t1.337235\n",
      "  validation loss:\t\t0.926457\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 55 of 500 took 0.830s\n",
      "  training loss:\t\t1.337185\n",
      "  validation loss:\t\t0.926045\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 56 of 500 took 0.840s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.928695\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 57 of 500 took 0.830s\n",
      "  training loss:\t\t1.337225\n",
      "  validation loss:\t\t0.926498\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 58 of 500 took 1.100s\n",
      "  training loss:\t\t1.337168\n",
      "  validation loss:\t\t0.926738\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 59 of 500 took 0.815s\n",
      "  training loss:\t\t1.337246\n",
      "  validation loss:\t\t0.926712\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 60 of 500 took 1.020s\n",
      "  training loss:\t\t1.337146\n",
      "  validation loss:\t\t0.928721\n",
      "  validation accuracy:\t\t86.32 %\n",
      "Epoch 61 of 500 took 0.833s\n",
      "  training loss:\t\t1.337321\n",
      "  validation loss:\t\t0.927099\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 62 of 500 took 0.838s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.927881\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 63 of 500 took 0.924s\n",
      "  training loss:\t\t1.337234\n",
      "  validation loss:\t\t0.928450\n",
      "  validation accuracy:\t\t86.33 %\n",
      "Epoch 64 of 500 took 0.831s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.925416\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 65 of 500 took 0.832s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.925927\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 66 of 500 took 0.897s\n",
      "  training loss:\t\t1.337262\n",
      "  validation loss:\t\t0.927474\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 67 of 500 took 0.811s\n",
      "  training loss:\t\t1.337212\n",
      "  validation loss:\t\t0.927755\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 68 of 500 took 0.812s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.926408\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 69 of 500 took 0.952s\n",
      "  training loss:\t\t1.337310\n",
      "  validation loss:\t\t0.926563\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 70 of 500 took 0.823s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.928334\n",
      "  validation accuracy:\t\t86.37 %\n",
      "Epoch 71 of 500 took 0.822s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.926021\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 72 of 500 took 0.803s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.928696\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 73 of 500 took 0.831s\n",
      "  training loss:\t\t1.337243\n",
      "  validation loss:\t\t0.929277\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 74 of 500 took 0.818s\n",
      "  training loss:\t\t1.337206\n",
      "  validation loss:\t\t0.926767\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 75 of 500 took 0.813s\n",
      "  training loss:\t\t1.337230\n",
      "  validation loss:\t\t0.926531\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 76 of 500 took 0.847s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.925881\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 77 of 500 took 0.904s\n",
      "  training loss:\t\t1.337140\n",
      "  validation loss:\t\t0.925848\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 78 of 500 took 0.807s\n",
      "  training loss:\t\t1.337274\n",
      "  validation loss:\t\t0.928552\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 79 of 500 took 0.926s\n",
      "  training loss:\t\t1.337221\n",
      "  validation loss:\t\t0.926760\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 80 of 500 took 0.802s\n",
      "  training loss:\t\t1.337210\n",
      "  validation loss:\t\t0.925925\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 81 of 500 took 0.804s\n",
      "  training loss:\t\t1.337208\n",
      "  validation loss:\t\t0.925898\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 82 of 500 took 0.805s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.925430\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 83 of 500 took 0.812s\n",
      "  training loss:\t\t1.337262\n",
      "  validation loss:\t\t0.926195\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 84 of 500 took 0.814s\n",
      "  training loss:\t\t1.337127\n",
      "  validation loss:\t\t0.927548\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 85 of 500 took 0.809s\n",
      "  training loss:\t\t1.337247\n",
      "  validation loss:\t\t0.928630\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 86 of 500 took 0.808s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.925378\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 87 of 500 took 0.808s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.926476\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 88 of 500 took 0.910s\n",
      "  training loss:\t\t1.337148\n",
      "  validation loss:\t\t0.927935\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 89 of 500 took 0.832s\n",
      "  training loss:\t\t1.337196\n",
      "  validation loss:\t\t0.926697\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 90 of 500 took 0.837s\n",
      "  training loss:\t\t1.337220\n",
      "  validation loss:\t\t0.926616\n",
      "  validation accuracy:\t\t85.91 %\n",
      "Epoch 91 of 500 took 0.821s\n",
      "  training loss:\t\t1.337282\n",
      "  validation loss:\t\t0.926056\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 92 of 500 took 0.828s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.925003\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 93 of 500 took 0.832s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.926155\n",
      "  validation accuracy:\t\t85.91 %\n",
      "Epoch 94 of 500 took 0.823s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.926947\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 95 of 500 took 0.845s\n",
      "  training loss:\t\t1.337268\n",
      "  validation loss:\t\t0.926797\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 96 of 500 took 1.058s\n",
      "  training loss:\t\t1.337248\n",
      "  validation loss:\t\t0.926156\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 97 of 500 took 0.815s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.927026\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 98 of 500 took 0.803s\n",
      "  training loss:\t\t1.337274\n",
      "  validation loss:\t\t0.925913\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 99 of 500 took 0.818s\n",
      "  training loss:\t\t1.337312\n",
      "  validation loss:\t\t0.927710\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 100 of 500 took 1.047s\n",
      "  training loss:\t\t1.337311\n",
      "  validation loss:\t\t0.927271\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 101 of 500 took 0.895s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.924706\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 102 of 500 took 0.849s\n",
      "  training loss:\t\t1.337221\n",
      "  validation loss:\t\t0.926789\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 103 of 500 took 0.821s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.926313\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 104 of 500 took 0.837s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.925929\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 105 of 500 took 0.807s\n",
      "  training loss:\t\t1.337219\n",
      "  validation loss:\t\t0.926056\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 106 of 500 took 0.835s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.927252\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 107 of 500 took 0.829s\n",
      "  training loss:\t\t1.337262\n",
      "  validation loss:\t\t0.927740\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 108 of 500 took 0.821s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.927724\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 109 of 500 took 0.838s\n",
      "  training loss:\t\t1.337258\n",
      "  validation loss:\t\t0.927510\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 110 of 500 took 0.806s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.928616\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 111 of 500 took 0.812s\n",
      "  training loss:\t\t1.337227\n",
      "  validation loss:\t\t0.926023\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 112 of 500 took 0.812s\n",
      "  training loss:\t\t1.337263\n",
      "  validation loss:\t\t0.924935\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 113 of 500 took 0.804s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.928117\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 114 of 500 took 0.844s\n",
      "  training loss:\t\t1.337201\n",
      "  validation loss:\t\t0.928254\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 115 of 500 took 1.003s\n",
      "  training loss:\t\t1.337238\n",
      "  validation loss:\t\t0.926047\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 116 of 500 took 0.830s\n",
      "  training loss:\t\t1.337139\n",
      "  validation loss:\t\t0.926170\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 117 of 500 took 0.810s\n",
      "  training loss:\t\t1.337175\n",
      "  validation loss:\t\t0.927029\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 118 of 500 took 0.818s\n",
      "  training loss:\t\t1.337165\n",
      "  validation loss:\t\t0.926261\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 119 of 500 took 0.929s\n",
      "  training loss:\t\t1.337224\n",
      "  validation loss:\t\t0.927444\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 120 of 500 took 0.807s\n",
      "  training loss:\t\t1.337195\n",
      "  validation loss:\t\t0.927972\n",
      "  validation accuracy:\t\t86.25 %\n",
      "Epoch 121 of 500 took 0.817s\n",
      "  training loss:\t\t1.337213\n",
      "  validation loss:\t\t0.925360\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 122 of 500 took 0.805s\n",
      "  training loss:\t\t1.337316\n",
      "  validation loss:\t\t0.928162\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 123 of 500 took 0.828s\n",
      "  training loss:\t\t1.337333\n",
      "  validation loss:\t\t0.926451\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 124 of 500 took 0.820s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.927151\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 125 of 500 took 0.910s\n",
      "  training loss:\t\t1.337306\n",
      "  validation loss:\t\t0.926295\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 126 of 500 took 0.818s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.927310\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 127 of 500 took 0.805s\n",
      "  training loss:\t\t1.337248\n",
      "  validation loss:\t\t0.927457\n",
      "  validation accuracy:\t\t86.27 %\n",
      "Epoch 128 of 500 took 0.824s\n",
      "  training loss:\t\t1.337313\n",
      "  validation loss:\t\t0.927996\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 129 of 500 took 0.822s\n",
      "  training loss:\t\t1.337181\n",
      "  validation loss:\t\t0.929043\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 130 of 500 took 0.831s\n",
      "  training loss:\t\t1.337254\n",
      "  validation loss:\t\t0.927911\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 131 of 500 took 0.804s\n",
      "  training loss:\t\t1.337280\n",
      "  validation loss:\t\t0.927230\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 132 of 500 took 0.865s\n",
      "  training loss:\t\t1.337294\n",
      "  validation loss:\t\t0.926288\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 133 of 500 took 0.826s\n",
      "  training loss:\t\t1.337291\n",
      "  validation loss:\t\t0.925823\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 134 of 500 took 0.973s\n",
      "  training loss:\t\t1.337188\n",
      "  validation loss:\t\t0.926053\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 135 of 500 took 0.818s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.925854\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 136 of 500 took 0.820s\n",
      "  training loss:\t\t1.337245\n",
      "  validation loss:\t\t0.926591\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 137 of 500 took 0.805s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.925762\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 138 of 500 took 0.818s\n",
      "  training loss:\t\t1.337284\n",
      "  validation loss:\t\t0.927332\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 139 of 500 took 0.928s\n",
      "  training loss:\t\t1.337278\n",
      "  validation loss:\t\t0.925644\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 140 of 500 took 0.806s\n",
      "  training loss:\t\t1.337166\n",
      "  validation loss:\t\t0.924531\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 141 of 500 took 0.829s\n",
      "  training loss:\t\t1.337202\n",
      "  validation loss:\t\t0.925494\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 142 of 500 took 0.829s\n",
      "  training loss:\t\t1.337226\n",
      "  validation loss:\t\t0.928167\n",
      "  validation accuracy:\t\t86.25 %\n",
      "Epoch 143 of 500 took 0.909s\n",
      "  training loss:\t\t1.337238\n",
      "  validation loss:\t\t0.927314\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 144 of 500 took 0.907s\n",
      "  training loss:\t\t1.337197\n",
      "  validation loss:\t\t0.928530\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 145 of 500 took 1.178s\n",
      "  training loss:\t\t1.337266\n",
      "  validation loss:\t\t0.925544\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 146 of 500 took 0.966s\n",
      "  training loss:\t\t1.337334\n",
      "  validation loss:\t\t0.927481\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 147 of 500 took 0.859s\n",
      "  training loss:\t\t1.337197\n",
      "  validation loss:\t\t0.926273\n",
      "  validation accuracy:\t\t86.23 %\n",
      "Epoch 148 of 500 took 0.871s\n",
      "  training loss:\t\t1.337241\n",
      "  validation loss:\t\t0.928034\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 149 of 500 took 0.958s\n",
      "  training loss:\t\t1.337279\n",
      "  validation loss:\t\t0.925716\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 150 of 500 took 0.840s\n",
      "  training loss:\t\t1.337169\n",
      "  validation loss:\t\t0.926139\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 151 of 500 took 0.819s\n",
      "  training loss:\t\t1.337221\n",
      "  validation loss:\t\t0.926477\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 152 of 500 took 0.924s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.928632\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 153 of 500 took 0.831s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.926654\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 154 of 500 took 0.906s\n",
      "  training loss:\t\t1.337300\n",
      "  validation loss:\t\t0.926969\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 155 of 500 took 0.806s\n",
      "  training loss:\t\t1.337143\n",
      "  validation loss:\t\t0.926769\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 156 of 500 took 0.809s\n",
      "  training loss:\t\t1.337233\n",
      "  validation loss:\t\t0.928675\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 157 of 500 took 0.820s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.926443\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 158 of 500 took 0.804s\n",
      "  training loss:\t\t1.337327\n",
      "  validation loss:\t\t0.927117\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 159 of 500 took 0.807s\n",
      "  training loss:\t\t1.337258\n",
      "  validation loss:\t\t0.926727\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 160 of 500 took 0.803s\n",
      "  training loss:\t\t1.337231\n",
      "  validation loss:\t\t0.925952\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 161 of 500 took 0.891s\n",
      "  training loss:\t\t1.337225\n",
      "  validation loss:\t\t0.925740\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 162 of 500 took 0.820s\n",
      "  training loss:\t\t1.337128\n",
      "  validation loss:\t\t0.925787\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 163 of 500 took 0.819s\n",
      "  training loss:\t\t1.337358\n",
      "  validation loss:\t\t0.925865\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 164 of 500 took 0.818s\n",
      "  training loss:\t\t1.337230\n",
      "  validation loss:\t\t0.926384\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 165 of 500 took 0.842s\n",
      "  training loss:\t\t1.337231\n",
      "  validation loss:\t\t0.927025\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 166 of 500 took 0.835s\n",
      "  training loss:\t\t1.337232\n",
      "  validation loss:\t\t0.927217\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 167 of 500 took 0.861s\n",
      "  training loss:\t\t1.337217\n",
      "  validation loss:\t\t0.926874\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 168 of 500 took 0.809s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.927913\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 169 of 500 took 0.817s\n",
      "  training loss:\t\t1.337316\n",
      "  validation loss:\t\t0.925812\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 170 of 500 took 0.818s\n",
      "  training loss:\t\t1.337184\n",
      "  validation loss:\t\t0.927080\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 171 of 500 took 0.881s\n",
      "  training loss:\t\t1.337189\n",
      "  validation loss:\t\t0.925823\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 172 of 500 took 0.807s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.927248\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 173 of 500 took 0.808s\n",
      "  training loss:\t\t1.337156\n",
      "  validation loss:\t\t0.927006\n",
      "  validation accuracy:\t\t86.24 %\n",
      "Epoch 174 of 500 took 0.812s\n",
      "  training loss:\t\t1.337225\n",
      "  validation loss:\t\t0.927354\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 175 of 500 took 0.814s\n",
      "  training loss:\t\t1.337217\n",
      "  validation loss:\t\t0.926228\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 176 of 500 took 0.833s\n",
      "  training loss:\t\t1.337301\n",
      "  validation loss:\t\t0.927377\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 177 of 500 took 0.807s\n",
      "  training loss:\t\t1.337329\n",
      "  validation loss:\t\t0.926102\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 178 of 500 took 0.938s\n",
      "  training loss:\t\t1.337289\n",
      "  validation loss:\t\t0.924100\n",
      "  validation accuracy:\t\t85.91 %\n",
      "Epoch 179 of 500 took 0.882s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.927773\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 180 of 500 took 0.800s\n",
      "  training loss:\t\t1.337192\n",
      "  validation loss:\t\t0.927289\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 181 of 500 took 0.821s\n",
      "  training loss:\t\t1.337273\n",
      "  validation loss:\t\t0.926066\n",
      "  validation accuracy:\t\t85.87 %\n",
      "Epoch 182 of 500 took 0.831s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.927727\n",
      "  validation accuracy:\t\t86.26 %\n",
      "Epoch 183 of 500 took 0.812s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.926774\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 184 of 500 took 0.829s\n",
      "  training loss:\t\t1.337175\n",
      "  validation loss:\t\t0.927934\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 185 of 500 took 0.836s\n",
      "  training loss:\t\t1.337272\n",
      "  validation loss:\t\t0.926017\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 186 of 500 took 0.882s\n",
      "  training loss:\t\t1.337212\n",
      "  validation loss:\t\t0.927492\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 187 of 500 took 0.874s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.926078\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 188 of 500 took 1.000s\n",
      "  training loss:\t\t1.337268\n",
      "  validation loss:\t\t0.925782\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 189 of 500 took 0.929s\n",
      "  training loss:\t\t1.337374\n",
      "  validation loss:\t\t0.927418\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 190 of 500 took 0.911s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.927047\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 191 of 500 took 0.861s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.926592\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 192 of 500 took 0.822s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.925416\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 193 of 500 took 1.005s\n",
      "  training loss:\t\t1.337299\n",
      "  validation loss:\t\t0.928146\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 194 of 500 took 0.836s\n",
      "  training loss:\t\t1.337242\n",
      "  validation loss:\t\t0.925809\n",
      "  validation accuracy:\t\t85.86 %\n",
      "Epoch 195 of 500 took 0.805s\n",
      "  training loss:\t\t1.337206\n",
      "  validation loss:\t\t0.925780\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 196 of 500 took 0.817s\n",
      "  training loss:\t\t1.337387\n",
      "  validation loss:\t\t0.927729\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 197 of 500 took 0.815s\n",
      "  training loss:\t\t1.337205\n",
      "  validation loss:\t\t0.927488\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 198 of 500 took 0.807s\n",
      "  training loss:\t\t1.337156\n",
      "  validation loss:\t\t0.927960\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 199 of 500 took 0.825s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.927544\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 200 of 500 took 0.812s\n",
      "  training loss:\t\t1.337221\n",
      "  validation loss:\t\t0.926328\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 201 of 500 took 0.821s\n",
      "  training loss:\t\t1.337112\n",
      "  validation loss:\t\t0.926974\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 202 of 500 took 0.846s\n",
      "  training loss:\t\t1.337179\n",
      "  validation loss:\t\t0.926309\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 203 of 500 took 0.843s\n",
      "  training loss:\t\t1.337254\n",
      "  validation loss:\t\t0.926495\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 204 of 500 took 0.811s\n",
      "  training loss:\t\t1.337251\n",
      "  validation loss:\t\t0.925978\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 205 of 500 took 0.835s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.926020\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 206 of 500 took 0.846s\n",
      "  training loss:\t\t1.337249\n",
      "  validation loss:\t\t0.927239\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 207 of 500 took 0.804s\n",
      "  training loss:\t\t1.337185\n",
      "  validation loss:\t\t0.925597\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 208 of 500 took 0.841s\n",
      "  training loss:\t\t1.337222\n",
      "  validation loss:\t\t0.927127\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 209 of 500 took 0.877s\n",
      "  training loss:\t\t1.337308\n",
      "  validation loss:\t\t0.926394\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 210 of 500 took 0.931s\n",
      "  training loss:\t\t1.337277\n",
      "  validation loss:\t\t0.926794\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 211 of 500 took 0.821s\n",
      "  training loss:\t\t1.337251\n",
      "  validation loss:\t\t0.926599\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 212 of 500 took 0.804s\n",
      "  training loss:\t\t1.337174\n",
      "  validation loss:\t\t0.925642\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 213 of 500 took 0.808s\n",
      "  training loss:\t\t1.337249\n",
      "  validation loss:\t\t0.927540\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 214 of 500 took 0.839s\n",
      "  training loss:\t\t1.337350\n",
      "  validation loss:\t\t0.927275\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 215 of 500 took 0.813s\n",
      "  training loss:\t\t1.337236\n",
      "  validation loss:\t\t0.926162\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 216 of 500 took 0.814s\n",
      "  training loss:\t\t1.337197\n",
      "  validation loss:\t\t0.926838\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 217 of 500 took 0.819s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.925235\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 218 of 500 took 0.811s\n",
      "  training loss:\t\t1.337341\n",
      "  validation loss:\t\t0.927539\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 219 of 500 took 0.808s\n",
      "  training loss:\t\t1.337289\n",
      "  validation loss:\t\t0.927312\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 220 of 500 took 0.817s\n",
      "  training loss:\t\t1.337331\n",
      "  validation loss:\t\t0.925689\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 221 of 500 took 0.810s\n",
      "  training loss:\t\t1.337176\n",
      "  validation loss:\t\t0.926874\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 222 of 500 took 0.833s\n",
      "  training loss:\t\t1.337155\n",
      "  validation loss:\t\t0.927923\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 223 of 500 took 0.813s\n",
      "  training loss:\t\t1.337148\n",
      "  validation loss:\t\t0.925214\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 224 of 500 took 0.908s\n",
      "  training loss:\t\t1.337236\n",
      "  validation loss:\t\t0.925807\n",
      "  validation accuracy:\t\t85.88 %\n",
      "Epoch 225 of 500 took 0.803s\n",
      "  training loss:\t\t1.337234\n",
      "  validation loss:\t\t0.926121\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 226 of 500 took 0.817s\n",
      "  training loss:\t\t1.337166\n",
      "  validation loss:\t\t0.927094\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 227 of 500 took 0.812s\n",
      "  training loss:\t\t1.337222\n",
      "  validation loss:\t\t0.927256\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 228 of 500 took 0.931s\n",
      "  training loss:\t\t1.337227\n",
      "  validation loss:\t\t0.926441\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 229 of 500 took 0.808s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.926393\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 230 of 500 took 0.799s\n",
      "  training loss:\t\t1.337239\n",
      "  validation loss:\t\t0.925917\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 231 of 500 took 0.799s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.925796\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 232 of 500 took 0.799s\n",
      "  training loss:\t\t1.337262\n",
      "  validation loss:\t\t0.927751\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 233 of 500 took 0.818s\n",
      "  training loss:\t\t1.337277\n",
      "  validation loss:\t\t0.928111\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 234 of 500 took 0.814s\n",
      "  training loss:\t\t1.337203\n",
      "  validation loss:\t\t0.925255\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 235 of 500 took 0.810s\n",
      "  training loss:\t\t1.337343\n",
      "  validation loss:\t\t0.925924\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 236 of 500 took 0.831s\n",
      "  training loss:\t\t1.337297\n",
      "  validation loss:\t\t0.926362\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 237 of 500 took 0.829s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.927630\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 238 of 500 took 0.824s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.927721\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 239 of 500 took 0.929s\n",
      "  training loss:\t\t1.337204\n",
      "  validation loss:\t\t0.925365\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 240 of 500 took 0.829s\n",
      "  training loss:\t\t1.337328\n",
      "  validation loss:\t\t0.927668\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 241 of 500 took 0.823s\n",
      "  training loss:\t\t1.337150\n",
      "  validation loss:\t\t0.926653\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 242 of 500 took 0.980s\n",
      "  training loss:\t\t1.337166\n",
      "  validation loss:\t\t0.927628\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 243 of 500 took 0.816s\n",
      "  training loss:\t\t1.337210\n",
      "  validation loss:\t\t0.926372\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 244 of 500 took 0.814s\n",
      "  training loss:\t\t1.337258\n",
      "  validation loss:\t\t0.926741\n",
      "  validation accuracy:\t\t85.81 %\n",
      "Epoch 245 of 500 took 0.806s\n",
      "  training loss:\t\t1.337316\n",
      "  validation loss:\t\t0.928568\n",
      "  validation accuracy:\t\t86.19 %\n",
      "Epoch 246 of 500 took 0.822s\n",
      "  training loss:\t\t1.337255\n",
      "  validation loss:\t\t0.926563\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 247 of 500 took 0.886s\n",
      "  training loss:\t\t1.337307\n",
      "  validation loss:\t\t0.928227\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 248 of 500 took 0.860s\n",
      "  training loss:\t\t1.337185\n",
      "  validation loss:\t\t0.925987\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 249 of 500 took 0.807s\n",
      "  training loss:\t\t1.337220\n",
      "  validation loss:\t\t0.928095\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 250 of 500 took 0.826s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.925197\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 251 of 500 took 0.818s\n",
      "  training loss:\t\t1.337274\n",
      "  validation loss:\t\t0.927582\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 252 of 500 took 0.811s\n",
      "  training loss:\t\t1.337319\n",
      "  validation loss:\t\t0.926957\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 253 of 500 took 0.801s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.926904\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 254 of 500 took 0.805s\n",
      "  training loss:\t\t1.337316\n",
      "  validation loss:\t\t0.927442\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 255 of 500 took 0.806s\n",
      "  training loss:\t\t1.337187\n",
      "  validation loss:\t\t0.927751\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 256 of 500 took 0.820s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.927431\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 257 of 500 took 0.928s\n",
      "  training loss:\t\t1.337266\n",
      "  validation loss:\t\t0.925671\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 258 of 500 took 0.826s\n",
      "  training loss:\t\t1.337139\n",
      "  validation loss:\t\t0.927530\n",
      "  validation accuracy:\t\t86.26 %\n",
      "Epoch 259 of 500 took 0.963s\n",
      "  training loss:\t\t1.337292\n",
      "  validation loss:\t\t0.926141\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 260 of 500 took 1.562s\n",
      "  training loss:\t\t1.337185\n",
      "  validation loss:\t\t0.926873\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 261 of 500 took 0.983s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.928867\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 262 of 500 took 1.231s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.926167\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 263 of 500 took 0.880s\n",
      "  training loss:\t\t1.337290\n",
      "  validation loss:\t\t0.927820\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 264 of 500 took 2.524s\n",
      "  training loss:\t\t1.337209\n",
      "  validation loss:\t\t0.927132\n",
      "  validation accuracy:\t\t86.24 %\n",
      "Epoch 265 of 500 took 1.911s\n",
      "  training loss:\t\t1.337293\n",
      "  validation loss:\t\t0.926642\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 266 of 500 took 1.733s\n",
      "  training loss:\t\t1.337314\n",
      "  validation loss:\t\t0.928629\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 267 of 500 took 2.040s\n",
      "  training loss:\t\t1.337210\n",
      "  validation loss:\t\t0.925440\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 268 of 500 took 2.029s\n",
      "  training loss:\t\t1.337250\n",
      "  validation loss:\t\t0.927053\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 269 of 500 took 1.832s\n",
      "  training loss:\t\t1.337329\n",
      "  validation loss:\t\t0.926998\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 270 of 500 took 1.559s\n",
      "  training loss:\t\t1.337205\n",
      "  validation loss:\t\t0.927649\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 271 of 500 took 1.676s\n",
      "  training loss:\t\t1.337255\n",
      "  validation loss:\t\t0.927149\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 272 of 500 took 1.506s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.926371\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 273 of 500 took 0.865s\n",
      "  training loss:\t\t1.337299\n",
      "  validation loss:\t\t0.925448\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 274 of 500 took 1.220s\n",
      "  training loss:\t\t1.337218\n",
      "  validation loss:\t\t0.927033\n",
      "  validation accuracy:\t\t86.29 %\n",
      "Epoch 275 of 500 took 1.125s\n",
      "  training loss:\t\t1.337342\n",
      "  validation loss:\t\t0.926069\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 276 of 500 took 0.922s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.927673\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 277 of 500 took 0.843s\n",
      "  training loss:\t\t1.337359\n",
      "  validation loss:\t\t0.927183\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 278 of 500 took 0.998s\n",
      "  training loss:\t\t1.337186\n",
      "  validation loss:\t\t0.926410\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 279 of 500 took 0.976s\n",
      "  training loss:\t\t1.337245\n",
      "  validation loss:\t\t0.926956\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 280 of 500 took 1.315s\n",
      "  training loss:\t\t1.337189\n",
      "  validation loss:\t\t0.927473\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 281 of 500 took 1.113s\n",
      "  training loss:\t\t1.337283\n",
      "  validation loss:\t\t0.926619\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 282 of 500 took 0.873s\n",
      "  training loss:\t\t1.337334\n",
      "  validation loss:\t\t0.927674\n",
      "  validation accuracy:\t\t85.86 %\n",
      "Epoch 283 of 500 took 0.830s\n",
      "  training loss:\t\t1.337306\n",
      "  validation loss:\t\t0.925326\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 284 of 500 took 0.942s\n",
      "  training loss:\t\t1.337304\n",
      "  validation loss:\t\t0.926646\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 285 of 500 took 1.033s\n",
      "  training loss:\t\t1.337238\n",
      "  validation loss:\t\t0.926674\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 286 of 500 took 0.890s\n",
      "  training loss:\t\t1.337186\n",
      "  validation loss:\t\t0.925746\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 287 of 500 took 0.876s\n",
      "  training loss:\t\t1.337248\n",
      "  validation loss:\t\t0.925272\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 288 of 500 took 0.875s\n",
      "  training loss:\t\t1.337299\n",
      "  validation loss:\t\t0.925963\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 289 of 500 took 1.057s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.926956\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 290 of 500 took 0.895s\n",
      "  training loss:\t\t1.337207\n",
      "  validation loss:\t\t0.925238\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 291 of 500 took 0.842s\n",
      "  training loss:\t\t1.337250\n",
      "  validation loss:\t\t0.925744\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 292 of 500 took 0.958s\n",
      "  training loss:\t\t1.337212\n",
      "  validation loss:\t\t0.927174\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 293 of 500 took 0.832s\n",
      "  training loss:\t\t1.337192\n",
      "  validation loss:\t\t0.927556\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 294 of 500 took 0.858s\n",
      "  training loss:\t\t1.337345\n",
      "  validation loss:\t\t0.927311\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 295 of 500 took 0.930s\n",
      "  training loss:\t\t1.337139\n",
      "  validation loss:\t\t0.925986\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 296 of 500 took 0.885s\n",
      "  training loss:\t\t1.337262\n",
      "  validation loss:\t\t0.926298\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 297 of 500 took 0.802s\n",
      "  training loss:\t\t1.337275\n",
      "  validation loss:\t\t0.927493\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 298 of 500 took 0.824s\n",
      "  training loss:\t\t1.337207\n",
      "  validation loss:\t\t0.926834\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 299 of 500 took 0.818s\n",
      "  training loss:\t\t1.337277\n",
      "  validation loss:\t\t0.926223\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 300 of 500 took 0.836s\n",
      "  training loss:\t\t1.337200\n",
      "  validation loss:\t\t0.927302\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 301 of 500 took 0.790s\n",
      "  training loss:\t\t1.337189\n",
      "  validation loss:\t\t0.928191\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 302 of 500 took 0.801s\n",
      "  training loss:\t\t1.337302\n",
      "  validation loss:\t\t0.927400\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 303 of 500 took 0.875s\n",
      "  training loss:\t\t1.337248\n",
      "  validation loss:\t\t0.926462\n",
      "  validation accuracy:\t\t85.73 %\n",
      "Epoch 304 of 500 took 0.827s\n",
      "  training loss:\t\t1.337292\n",
      "  validation loss:\t\t0.926541\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 305 of 500 took 0.808s\n",
      "  training loss:\t\t1.337286\n",
      "  validation loss:\t\t0.927290\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 306 of 500 took 0.818s\n",
      "  training loss:\t\t1.337226\n",
      "  validation loss:\t\t0.926501\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 307 of 500 took 0.831s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.927680\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 308 of 500 took 0.823s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.926197\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 309 of 500 took 0.933s\n",
      "  training loss:\t\t1.337331\n",
      "  validation loss:\t\t0.926932\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 310 of 500 took 0.789s\n",
      "  training loss:\t\t1.337178\n",
      "  validation loss:\t\t0.927648\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 311 of 500 took 0.789s\n",
      "  training loss:\t\t1.337371\n",
      "  validation loss:\t\t0.929100\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 312 of 500 took 0.852s\n",
      "  training loss:\t\t1.337324\n",
      "  validation loss:\t\t0.927085\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 313 of 500 took 0.905s\n",
      "  training loss:\t\t1.337227\n",
      "  validation loss:\t\t0.926462\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 314 of 500 took 0.868s\n",
      "  training loss:\t\t1.337127\n",
      "  validation loss:\t\t0.925411\n",
      "  validation accuracy:\t\t85.78 %\n",
      "Epoch 315 of 500 took 1.033s\n",
      "  training loss:\t\t1.337312\n",
      "  validation loss:\t\t0.927955\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 316 of 500 took 0.836s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.926724\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 317 of 500 took 1.238s\n",
      "  training loss:\t\t1.337307\n",
      "  validation loss:\t\t0.926539\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 318 of 500 took 1.438s\n",
      "  training loss:\t\t1.337233\n",
      "  validation loss:\t\t0.927738\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 319 of 500 took 1.115s\n",
      "  training loss:\t\t1.337259\n",
      "  validation loss:\t\t0.927731\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 320 of 500 took 2.210s\n",
      "  training loss:\t\t1.337274\n",
      "  validation loss:\t\t0.927065\n",
      "  validation accuracy:\t\t86.23 %\n",
      "Epoch 321 of 500 took 1.098s\n",
      "  training loss:\t\t1.337191\n",
      "  validation loss:\t\t0.926159\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 322 of 500 took 0.810s\n",
      "  training loss:\t\t1.337158\n",
      "  validation loss:\t\t0.926246\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 323 of 500 took 0.814s\n",
      "  training loss:\t\t1.337186\n",
      "  validation loss:\t\t0.927223\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 324 of 500 took 0.865s\n",
      "  training loss:\t\t1.337378\n",
      "  validation loss:\t\t0.926417\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 325 of 500 took 1.040s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.928152\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 326 of 500 took 0.925s\n",
      "  training loss:\t\t1.337235\n",
      "  validation loss:\t\t0.928553\n",
      "  validation accuracy:\t\t86.22 %\n",
      "Epoch 327 of 500 took 0.880s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.927702\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 328 of 500 took 0.885s\n",
      "  training loss:\t\t1.337279\n",
      "  validation loss:\t\t0.927737\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 329 of 500 took 0.980s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.925445\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 330 of 500 took 0.903s\n",
      "  training loss:\t\t1.337201\n",
      "  validation loss:\t\t0.927158\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 331 of 500 took 0.828s\n",
      "  training loss:\t\t1.337249\n",
      "  validation loss:\t\t0.926682\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 332 of 500 took 0.863s\n",
      "  training loss:\t\t1.337230\n",
      "  validation loss:\t\t0.927296\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 333 of 500 took 0.831s\n",
      "  training loss:\t\t1.337265\n",
      "  validation loss:\t\t0.926100\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 334 of 500 took 0.811s\n",
      "  training loss:\t\t1.337249\n",
      "  validation loss:\t\t0.927301\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 335 of 500 took 0.850s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.925687\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 336 of 500 took 0.838s\n",
      "  training loss:\t\t1.337161\n",
      "  validation loss:\t\t0.925806\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 337 of 500 took 0.934s\n",
      "  training loss:\t\t1.337297\n",
      "  validation loss:\t\t0.926514\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 338 of 500 took 0.824s\n",
      "  training loss:\t\t1.337184\n",
      "  validation loss:\t\t0.926282\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 339 of 500 took 0.820s\n",
      "  training loss:\t\t1.337220\n",
      "  validation loss:\t\t0.925704\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 340 of 500 took 0.812s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.928839\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 341 of 500 took 0.826s\n",
      "  training loss:\t\t1.337217\n",
      "  validation loss:\t\t0.927681\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 342 of 500 took 0.934s\n",
      "  training loss:\t\t1.337316\n",
      "  validation loss:\t\t0.927328\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 343 of 500 took 0.900s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.926560\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 344 of 500 took 0.796s\n",
      "  training loss:\t\t1.337286\n",
      "  validation loss:\t\t0.928402\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 345 of 500 took 0.785s\n",
      "  training loss:\t\t1.337248\n",
      "  validation loss:\t\t0.925822\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 346 of 500 took 0.812s\n",
      "  training loss:\t\t1.337226\n",
      "  validation loss:\t\t0.925483\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 347 of 500 took 0.885s\n",
      "  training loss:\t\t1.337317\n",
      "  validation loss:\t\t0.927776\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 348 of 500 took 0.811s\n",
      "  training loss:\t\t1.337213\n",
      "  validation loss:\t\t0.926829\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 349 of 500 took 0.809s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.926628\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 350 of 500 took 0.804s\n",
      "  training loss:\t\t1.337205\n",
      "  validation loss:\t\t0.927593\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 351 of 500 took 0.794s\n",
      "  training loss:\t\t1.337221\n",
      "  validation loss:\t\t0.926652\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 352 of 500 took 0.877s\n",
      "  training loss:\t\t1.337190\n",
      "  validation loss:\t\t0.926871\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 353 of 500 took 0.843s\n",
      "  training loss:\t\t1.337226\n",
      "  validation loss:\t\t0.926692\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 354 of 500 took 0.854s\n",
      "  training loss:\t\t1.337299\n",
      "  validation loss:\t\t0.927050\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 355 of 500 took 0.872s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.927084\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 356 of 500 took 0.842s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.925671\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 357 of 500 took 0.796s\n",
      "  training loss:\t\t1.337241\n",
      "  validation loss:\t\t0.926600\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 358 of 500 took 0.802s\n",
      "  training loss:\t\t1.337337\n",
      "  validation loss:\t\t0.926623\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 359 of 500 took 0.925s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.926890\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 360 of 500 took 0.871s\n",
      "  training loss:\t\t1.337165\n",
      "  validation loss:\t\t0.927729\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 361 of 500 took 0.843s\n",
      "  training loss:\t\t1.337298\n",
      "  validation loss:\t\t0.926290\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 362 of 500 took 1.013s\n",
      "  training loss:\t\t1.337301\n",
      "  validation loss:\t\t0.925538\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 363 of 500 took 0.824s\n",
      "  training loss:\t\t1.337181\n",
      "  validation loss:\t\t0.925976\n",
      "  validation accuracy:\t\t85.87 %\n",
      "Epoch 364 of 500 took 0.833s\n",
      "  training loss:\t\t1.337267\n",
      "  validation loss:\t\t0.927259\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 365 of 500 took 0.812s\n",
      "  training loss:\t\t1.337286\n",
      "  validation loss:\t\t0.927880\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 366 of 500 took 0.814s\n",
      "  training loss:\t\t1.337227\n",
      "  validation loss:\t\t0.925581\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 367 of 500 took 0.807s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.928291\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 368 of 500 took 0.865s\n",
      "  training loss:\t\t1.337198\n",
      "  validation loss:\t\t0.926477\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 369 of 500 took 0.850s\n",
      "  training loss:\t\t1.337358\n",
      "  validation loss:\t\t0.925512\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 370 of 500 took 0.789s\n",
      "  training loss:\t\t1.337244\n",
      "  validation loss:\t\t0.926664\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 371 of 500 took 0.954s\n",
      "  training loss:\t\t1.337287\n",
      "  validation loss:\t\t0.928989\n",
      "  validation accuracy:\t\t86.30 %\n",
      "Epoch 372 of 500 took 0.814s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.927774\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 373 of 500 took 0.821s\n",
      "  training loss:\t\t1.337323\n",
      "  validation loss:\t\t0.927403\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 374 of 500 took 0.817s\n",
      "  training loss:\t\t1.337199\n",
      "  validation loss:\t\t0.926998\n",
      "  validation accuracy:\t\t85.88 %\n",
      "Epoch 375 of 500 took 0.885s\n",
      "  training loss:\t\t1.337340\n",
      "  validation loss:\t\t0.928712\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 376 of 500 took 0.884s\n",
      "  training loss:\t\t1.337285\n",
      "  validation loss:\t\t0.927175\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 377 of 500 took 0.803s\n",
      "  training loss:\t\t1.337188\n",
      "  validation loss:\t\t0.928026\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 378 of 500 took 0.914s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.925287\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 379 of 500 took 0.838s\n",
      "  training loss:\t\t1.337164\n",
      "  validation loss:\t\t0.925723\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 380 of 500 took 0.852s\n",
      "  training loss:\t\t1.337206\n",
      "  validation loss:\t\t0.926536\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 381 of 500 took 0.851s\n",
      "  training loss:\t\t1.337173\n",
      "  validation loss:\t\t0.925990\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 382 of 500 took 0.813s\n",
      "  training loss:\t\t1.337273\n",
      "  validation loss:\t\t0.928461\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 383 of 500 took 0.836s\n",
      "  training loss:\t\t1.337229\n",
      "  validation loss:\t\t0.926835\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 384 of 500 took 0.820s\n",
      "  training loss:\t\t1.337264\n",
      "  validation loss:\t\t0.925577\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 385 of 500 took 0.794s\n",
      "  training loss:\t\t1.337228\n",
      "  validation loss:\t\t0.927154\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 386 of 500 took 0.802s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.926720\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 387 of 500 took 0.813s\n",
      "  training loss:\t\t1.337267\n",
      "  validation loss:\t\t0.926678\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 388 of 500 took 0.796s\n",
      "  training loss:\t\t1.337322\n",
      "  validation loss:\t\t0.926655\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 389 of 500 took 0.791s\n",
      "  training loss:\t\t1.337220\n",
      "  validation loss:\t\t0.927250\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 390 of 500 took 0.801s\n",
      "  training loss:\t\t1.337203\n",
      "  validation loss:\t\t0.926104\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 391 of 500 took 0.802s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.926300\n",
      "  validation accuracy:\t\t86.25 %\n",
      "Epoch 392 of 500 took 0.792s\n",
      "  training loss:\t\t1.337261\n",
      "  validation loss:\t\t0.925918\n",
      "  validation accuracy:\t\t85.93 %\n",
      "Epoch 393 of 500 took 0.797s\n",
      "  training loss:\t\t1.337172\n",
      "  validation loss:\t\t0.927755\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 394 of 500 took 0.796s\n",
      "  training loss:\t\t1.337210\n",
      "  validation loss:\t\t0.927161\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 395 of 500 took 0.814s\n",
      "  training loss:\t\t1.337251\n",
      "  validation loss:\t\t0.925873\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 396 of 500 took 0.790s\n",
      "  training loss:\t\t1.337177\n",
      "  validation loss:\t\t0.928116\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 397 of 500 took 0.788s\n",
      "  training loss:\t\t1.337265\n",
      "  validation loss:\t\t0.928079\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 398 of 500 took 0.786s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.927040\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 399 of 500 took 0.834s\n",
      "  training loss:\t\t1.337260\n",
      "  validation loss:\t\t0.927740\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 400 of 500 took 0.882s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.926031\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 401 of 500 took 0.813s\n",
      "  training loss:\t\t1.337208\n",
      "  validation loss:\t\t0.927301\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 402 of 500 took 0.806s\n",
      "  training loss:\t\t1.337250\n",
      "  validation loss:\t\t0.926368\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 403 of 500 took 0.791s\n",
      "  training loss:\t\t1.337350\n",
      "  validation loss:\t\t0.927031\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 404 of 500 took 0.787s\n",
      "  training loss:\t\t1.337283\n",
      "  validation loss:\t\t0.926933\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 405 of 500 took 0.792s\n",
      "  training loss:\t\t1.337222\n",
      "  validation loss:\t\t0.925857\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 406 of 500 took 0.792s\n",
      "  training loss:\t\t1.337200\n",
      "  validation loss:\t\t0.925490\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 407 of 500 took 0.820s\n",
      "  training loss:\t\t1.337304\n",
      "  validation loss:\t\t0.925013\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 408 of 500 took 0.808s\n",
      "  training loss:\t\t1.337247\n",
      "  validation loss:\t\t0.927049\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 409 of 500 took 0.824s\n",
      "  training loss:\t\t1.337271\n",
      "  validation loss:\t\t0.928639\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 410 of 500 took 0.806s\n",
      "  training loss:\t\t1.337201\n",
      "  validation loss:\t\t0.926665\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 411 of 500 took 0.793s\n",
      "  training loss:\t\t1.337337\n",
      "  validation loss:\t\t0.926864\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 412 of 500 took 0.798s\n",
      "  training loss:\t\t1.337220\n",
      "  validation loss:\t\t0.925449\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 413 of 500 took 0.787s\n",
      "  training loss:\t\t1.337251\n",
      "  validation loss:\t\t0.926310\n",
      "  validation accuracy:\t\t85.86 %\n",
      "Epoch 414 of 500 took 0.810s\n",
      "  training loss:\t\t1.337245\n",
      "  validation loss:\t\t0.925901\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 415 of 500 took 0.806s\n",
      "  training loss:\t\t1.337281\n",
      "  validation loss:\t\t0.926101\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 416 of 500 took 0.797s\n",
      "  training loss:\t\t1.337270\n",
      "  validation loss:\t\t0.926449\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 417 of 500 took 0.797s\n",
      "  training loss:\t\t1.337256\n",
      "  validation loss:\t\t0.925624\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 418 of 500 took 0.788s\n",
      "  training loss:\t\t1.337212\n",
      "  validation loss:\t\t0.927526\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 419 of 500 took 0.793s\n",
      "  training loss:\t\t1.337246\n",
      "  validation loss:\t\t0.927198\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 420 of 500 took 0.841s\n",
      "  training loss:\t\t1.337211\n",
      "  validation loss:\t\t0.926106\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 421 of 500 took 0.837s\n",
      "  training loss:\t\t1.337267\n",
      "  validation loss:\t\t0.927148\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 422 of 500 took 0.813s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.926413\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 423 of 500 took 0.806s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.928001\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 424 of 500 took 0.785s\n",
      "  training loss:\t\t1.337245\n",
      "  validation loss:\t\t0.926545\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 425 of 500 took 0.788s\n",
      "  training loss:\t\t1.337195\n",
      "  validation loss:\t\t0.926770\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 426 of 500 took 0.786s\n",
      "  training loss:\t\t1.337257\n",
      "  validation loss:\t\t0.925986\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 427 of 500 took 0.923s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.926468\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 428 of 500 took 0.886s\n",
      "  training loss:\t\t1.337252\n",
      "  validation loss:\t\t0.925449\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 429 of 500 took 0.900s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.927509\n",
      "  validation accuracy:\t\t86.13 %\n",
      "Epoch 430 of 500 took 0.794s\n",
      "  training loss:\t\t1.337218\n",
      "  validation loss:\t\t0.926525\n",
      "  validation accuracy:\t\t86.19 %\n",
      "Epoch 431 of 500 took 0.817s\n",
      "  training loss:\t\t1.337243\n",
      "  validation loss:\t\t0.926183\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 432 of 500 took 0.800s\n",
      "  training loss:\t\t1.337180\n",
      "  validation loss:\t\t0.927756\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 433 of 500 took 0.814s\n",
      "  training loss:\t\t1.337277\n",
      "  validation loss:\t\t0.927869\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 434 of 500 took 0.804s\n",
      "  training loss:\t\t1.337203\n",
      "  validation loss:\t\t0.928198\n",
      "  validation accuracy:\t\t86.09 %\n",
      "Epoch 435 of 500 took 0.797s\n",
      "  training loss:\t\t1.337219\n",
      "  validation loss:\t\t0.926850\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 436 of 500 took 0.840s\n",
      "  training loss:\t\t1.337264\n",
      "  validation loss:\t\t0.925231\n",
      "  validation accuracy:\t\t86.06 %\n",
      "Epoch 437 of 500 took 0.800s\n",
      "  training loss:\t\t1.337214\n",
      "  validation loss:\t\t0.926886\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Epoch 438 of 500 took 0.790s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.927023\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 439 of 500 took 0.835s\n",
      "  training loss:\t\t1.337242\n",
      "  validation loss:\t\t0.926875\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 440 of 500 took 0.883s\n",
      "  training loss:\t\t1.337259\n",
      "  validation loss:\t\t0.926659\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 441 of 500 took 0.904s\n",
      "  training loss:\t\t1.337237\n",
      "  validation loss:\t\t0.927495\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 442 of 500 took 1.618s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.927847\n",
      "  validation accuracy:\t\t86.17 %\n",
      "Epoch 443 of 500 took 1.270s\n",
      "  training loss:\t\t1.337277\n",
      "  validation loss:\t\t0.927333\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 444 of 500 took 0.826s\n",
      "  training loss:\t\t1.337304\n",
      "  validation loss:\t\t0.927029\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 445 of 500 took 0.811s\n",
      "  training loss:\t\t1.337206\n",
      "  validation loss:\t\t0.926525\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 446 of 500 took 1.147s\n",
      "  training loss:\t\t1.337298\n",
      "  validation loss:\t\t0.928022\n",
      "  validation accuracy:\t\t85.88 %\n",
      "Epoch 447 of 500 took 0.995s\n",
      "  training loss:\t\t1.337286\n",
      "  validation loss:\t\t0.926713\n",
      "  validation accuracy:\t\t85.89 %\n",
      "Epoch 448 of 500 took 1.182s\n",
      "  training loss:\t\t1.337157\n",
      "  validation loss:\t\t0.926217\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 449 of 500 took 1.813s\n",
      "  training loss:\t\t1.337290\n",
      "  validation loss:\t\t0.927899\n",
      "  validation accuracy:\t\t86.21 %\n",
      "Epoch 450 of 500 took 0.955s\n",
      "  training loss:\t\t1.337160\n",
      "  validation loss:\t\t0.928051\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 451 of 500 took 0.889s\n",
      "  training loss:\t\t1.337279\n",
      "  validation loss:\t\t0.926119\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 452 of 500 took 0.840s\n",
      "  training loss:\t\t1.337293\n",
      "  validation loss:\t\t0.926336\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 453 of 500 took 0.789s\n",
      "  training loss:\t\t1.337272\n",
      "  validation loss:\t\t0.925844\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 454 of 500 took 0.785s\n",
      "  training loss:\t\t1.337239\n",
      "  validation loss:\t\t0.923918\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 455 of 500 took 1.234s\n",
      "  training loss:\t\t1.337239\n",
      "  validation loss:\t\t0.925697\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 456 of 500 took 0.812s\n",
      "  training loss:\t\t1.337225\n",
      "  validation loss:\t\t0.927419\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 457 of 500 took 0.778s\n",
      "  training loss:\t\t1.337209\n",
      "  validation loss:\t\t0.928630\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 458 of 500 took 0.814s\n",
      "  training loss:\t\t1.337242\n",
      "  validation loss:\t\t0.926041\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 459 of 500 took 0.870s\n",
      "  training loss:\t\t1.337306\n",
      "  validation loss:\t\t0.926999\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 460 of 500 took 0.823s\n",
      "  training loss:\t\t1.337197\n",
      "  validation loss:\t\t0.926442\n",
      "  validation accuracy:\t\t85.97 %\n",
      "Epoch 461 of 500 took 0.856s\n",
      "  training loss:\t\t1.337126\n",
      "  validation loss:\t\t0.925485\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 462 of 500 took 0.851s\n",
      "  training loss:\t\t1.337160\n",
      "  validation loss:\t\t0.926828\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 463 of 500 took 1.127s\n",
      "  training loss:\t\t1.337296\n",
      "  validation loss:\t\t0.927159\n",
      "  validation accuracy:\t\t86.18 %\n",
      "Epoch 464 of 500 took 0.899s\n",
      "  training loss:\t\t1.337207\n",
      "  validation loss:\t\t0.926786\n",
      "  validation accuracy:\t\t85.99 %\n",
      "Epoch 465 of 500 took 0.921s\n",
      "  training loss:\t\t1.337240\n",
      "  validation loss:\t\t0.926455\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 466 of 500 took 0.965s\n",
      "  training loss:\t\t1.337249\n",
      "  validation loss:\t\t0.928416\n",
      "  validation accuracy:\t\t86.11 %\n",
      "Epoch 467 of 500 took 0.880s\n",
      "  training loss:\t\t1.337332\n",
      "  validation loss:\t\t0.927037\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 468 of 500 took 0.852s\n",
      "  training loss:\t\t1.337179\n",
      "  validation loss:\t\t0.927144\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 469 of 500 took 0.822s\n",
      "  training loss:\t\t1.337300\n",
      "  validation loss:\t\t0.928358\n",
      "  validation accuracy:\t\t86.04 %\n",
      "Epoch 470 of 500 took 0.818s\n",
      "  training loss:\t\t1.337243\n",
      "  validation loss:\t\t0.928316\n",
      "  validation accuracy:\t\t86.20 %\n",
      "Epoch 471 of 500 took 0.822s\n",
      "  training loss:\t\t1.337273\n",
      "  validation loss:\t\t0.926520\n",
      "  validation accuracy:\t\t86.01 %\n",
      "Epoch 472 of 500 took 1.081s\n",
      "  training loss:\t\t1.337179\n",
      "  validation loss:\t\t0.927477\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 473 of 500 took 1.261s\n",
      "  training loss:\t\t1.337253\n",
      "  validation loss:\t\t0.928245\n",
      "  validation accuracy:\t\t86.02 %\n",
      "Epoch 474 of 500 took 0.939s\n",
      "  training loss:\t\t1.337252\n",
      "  validation loss:\t\t0.926235\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 475 of 500 took 1.043s\n",
      "  training loss:\t\t1.337311\n",
      "  validation loss:\t\t0.926859\n",
      "  validation accuracy:\t\t85.98 %\n",
      "Epoch 476 of 500 took 1.298s\n",
      "  training loss:\t\t1.337193\n",
      "  validation loss:\t\t0.926848\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 477 of 500 took 0.878s\n",
      "  training loss:\t\t1.337258\n",
      "  validation loss:\t\t0.926514\n",
      "  validation accuracy:\t\t86.12 %\n",
      "Epoch 478 of 500 took 0.840s\n",
      "  training loss:\t\t1.337225\n",
      "  validation loss:\t\t0.925293\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 479 of 500 took 0.957s\n",
      "  training loss:\t\t1.337263\n",
      "  validation loss:\t\t0.929300\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 480 of 500 took 1.016s\n",
      "  training loss:\t\t1.337142\n",
      "  validation loss:\t\t0.925246\n",
      "  validation accuracy:\t\t85.94 %\n",
      "Epoch 481 of 500 took 0.885s\n",
      "  training loss:\t\t1.337189\n",
      "  validation loss:\t\t0.926117\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 482 of 500 took 1.104s\n",
      "  training loss:\t\t1.337328\n",
      "  validation loss:\t\t0.925123\n",
      "  validation accuracy:\t\t86.00 %\n",
      "Epoch 483 of 500 took 0.957s\n",
      "  training loss:\t\t1.337276\n",
      "  validation loss:\t\t0.926230\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 484 of 500 took 1.117s\n",
      "  training loss:\t\t1.337201\n",
      "  validation loss:\t\t0.927010\n",
      "  validation accuracy:\t\t86.10 %\n",
      "Epoch 485 of 500 took 0.987s\n",
      "  training loss:\t\t1.337222\n",
      "  validation loss:\t\t0.925943\n",
      "  validation accuracy:\t\t85.83 %\n",
      "Epoch 486 of 500 took 0.831s\n",
      "  training loss:\t\t1.337297\n",
      "  validation loss:\t\t0.927311\n",
      "  validation accuracy:\t\t85.87 %\n",
      "Epoch 487 of 500 took 0.971s\n",
      "  training loss:\t\t1.337265\n",
      "  validation loss:\t\t0.927480\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 488 of 500 took 0.858s\n",
      "  training loss:\t\t1.337259\n",
      "  validation loss:\t\t0.927683\n",
      "  validation accuracy:\t\t85.90 %\n",
      "Epoch 489 of 500 took 1.101s\n",
      "  training loss:\t\t1.337202\n",
      "  validation loss:\t\t0.926557\n",
      "  validation accuracy:\t\t85.95 %\n",
      "Epoch 490 of 500 took 1.270s\n",
      "  training loss:\t\t1.337234\n",
      "  validation loss:\t\t0.927680\n",
      "  validation accuracy:\t\t86.03 %\n",
      "Epoch 491 of 500 took 1.125s\n",
      "  training loss:\t\t1.337266\n",
      "  validation loss:\t\t0.927367\n",
      "  validation accuracy:\t\t85.85 %\n",
      "Epoch 492 of 500 took 1.381s\n",
      "  training loss:\t\t1.337223\n",
      "  validation loss:\t\t0.928850\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 493 of 500 took 1.225s\n",
      "  training loss:\t\t1.337288\n",
      "  validation loss:\t\t0.927161\n",
      "  validation accuracy:\t\t86.07 %\n",
      "Epoch 494 of 500 took 1.116s\n",
      "  training loss:\t\t1.337163\n",
      "  validation loss:\t\t0.925831\n",
      "  validation accuracy:\t\t85.92 %\n",
      "Epoch 495 of 500 took 0.811s\n",
      "  training loss:\t\t1.337185\n",
      "  validation loss:\t\t0.927676\n",
      "  validation accuracy:\t\t86.22 %\n",
      "Epoch 496 of 500 took 0.897s\n",
      "  training loss:\t\t1.337292\n",
      "  validation loss:\t\t0.926942\n",
      "  validation accuracy:\t\t86.14 %\n",
      "Epoch 497 of 500 took 1.253s\n",
      "  training loss:\t\t1.337198\n",
      "  validation loss:\t\t0.927883\n",
      "  validation accuracy:\t\t86.08 %\n",
      "Epoch 498 of 500 took 0.997s\n",
      "  training loss:\t\t1.337215\n",
      "  validation loss:\t\t0.928210\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Epoch 499 of 500 took 0.906s\n",
      "  training loss:\t\t1.337254\n",
      "  validation loss:\t\t0.926909\n",
      "  validation accuracy:\t\t86.16 %\n",
      "Epoch 500 of 500 took 0.829s\n",
      "  training loss:\t\t1.337267\n",
      "  validation loss:\t\t0.926191\n",
      "  validation accuracy:\t\t85.96 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.937099\n",
      "  test accuracy:\t\t85.12 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "#X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model (depending on first command line parameter)\n",
    "print(\"Building model and compiling functions...\")\n",
    "\n",
    "num_epochs=500\n",
    "\n",
    "depth=0 \n",
    "width=0\n",
    "drop_in=0 \n",
    "drop_hid=0\n",
    "network = build_custom_mlp(input_var, int(depth), int(width), float(drop_in), float(drop_hid))\n",
    "\n",
    "\n",
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "l2_penalty=lasagne.regularization.regularize_layer_params(network,l2)*1\n",
    "loss=loss+l2_penalty/10\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "eval_fn=theano.function([input_var,target_var],loss)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "predict_fn=theano.function([input_var],T.argmax(test_prediction, axis=1))\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train_dr, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val_dr, y_val, 1, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    #print(\"{}\".format(inputs))\n",
    "    #print(\"{}\".format(targets+1))\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "#After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test_dr, y_test, 500, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "\n",
    "# Optionally, you could now dump the network weights to a file like this:\n",
    "# np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "#\n",
    "# And load them again later on like this:\n",
    "# with np.load('model.npz') as f:\n",
    "#     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "# lasagne.layers.set_all_param_values(network, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class is [7]\n",
      "Actual class is [8]\n",
      "Actual class is [7]\n",
      "Actual class is [1]\n",
      "Actual class is [3]\n",
      "Actual class is [6]\n",
      "Actual class is [4]\n",
      "Actual class is [5]\n",
      "Actual class is [2]\n",
      "Actual class is [0]\n",
      "% of misclassified examples is 97.7528089888\n",
      "Deviation is 0.478713768818\n"
     ]
    }
   ],
   "source": [
    "outer_loop=np.random.randint(0,10000,10)\n",
    "count_wrong=0.0\n",
    "count_tot=0.0\n",
    "deviation=0.0\n",
    "for old_class in outer_loop:\n",
    "    def f(x):\n",
    "        return x[0]*np.sum(np.absolute(x[1:]))+eval_fn(X_curr+x[1:].reshape(1,1,rd),y_curr)\n",
    "    X_curr=np.copy(X_train_dr[old_class].reshape(1,1,rd))\n",
    "    X_curr_flat=X_curr.flatten()\n",
    "    y_old=np.copy(y_train[old_class].reshape((1,)))\n",
    "    print (\"Actual class is {}\".format(y_old))\n",
    "    upper_limit=np.ones(rd)-X_curr_flat\n",
    "    lower_limit=np.zeros(rd)-X_curr_flat\n",
    "    bound=zip(lower_limit,upper_limit)\n",
    "    bound.insert(0,(0,None))\n",
    "    inner_loop=np.random.randint(0,10000,10)\n",
    "    for i in inner_loop:\n",
    "        y_curr=np.copy(y_train[i].reshape((1,)))\n",
    "        if y_curr==y_old:\n",
    "            continue\n",
    "        #print (\"Target class is {}\".format(y_curr))\n",
    "        x_0=np.zeros(rd+1)\n",
    "        r,fval,info=scipy.optimize.fmin_l_bfgs_b(f,x_0,approx_grad=1,bounds=bound)\n",
    "        #r_mat=r[1:].reshape((28,28))\n",
    "        #loss_actual_ini=eval_fn(X_curr,y_old)\n",
    "        #loss_induced_ini=eval_fn(X_curr,y_curr)\n",
    "        #loss_induced_final=eval_fn(X_curr+r[1:].reshape((1,1,28,28)),y_curr)\n",
    "        #loss_actual_ini=eval_fn(X_curr+r[1:].reshape((1,1,28,28)),y_old)\n",
    "        prediction_curr=predict_fn(X_curr+r[1:].reshape((1,1,rd)))\n",
    "        if prediction_curr!=predict_fn(X_curr):\n",
    "            count_wrong=count_wrong+1\n",
    "            deviation=deviation+np.sqrt(np.sum(r[1:]**2)/rd)\n",
    "        #modified_image=(X_curr+r[1:].reshape((1,1,28,28))).reshape((28,28))\n",
    "        label_array=np.concatenate((y_old,y_curr,prediction_curr, old_class.reshape((1,)),i.reshape((1,))))\n",
    "        count_tot=count_tot+1\n",
    "if count_wrong!=0:\n",
    "    avg_deviation=deviation/count_wrong\n",
    "else:\n",
    "    avg_deviation=deviation/count_tot\n",
    "print (\"% of misclassified examples is {}\".format(count_wrong/count_tot*100))\n",
    "print (\"Deviation is {}\".format(avg_deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

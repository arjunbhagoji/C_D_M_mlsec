{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 784)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_in_train=X_train.reshape(50000,784)\n",
    "PCA_in_val=X_val.reshape(10000,784)\n",
    "PCA_in_test=X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_columns=[]\n",
    "for i in range(784):\n",
    "    if np.std(PCA_in_train[:,i])!=0.0:\n",
    "        rel_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_in_train_nz=PCA_in_train[:,rel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 717)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_in_train_nz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_columns_v=[]\n",
    "for i in range(784):\n",
    "    if np.std(PCA_in_val[:,i])!=0.0:\n",
    "        rel_columns_v.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel_columns_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_columns_t=[]\n",
    "for i in range(784):\n",
    "    if np.std(PCA_in_test[:,i])!=0.0:\n",
    "        rel_columns_t.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel_columns_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_in_val_nz=PCA_in_val[:,rel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_in_test_nz=PCA_in_test[:,rel_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing PCA over the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train=pca.fit(PCA_in_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PCA_out_train=PCA(PCA_in_train,standardize=False)\n",
    "\n",
    "var_sum=0\n",
    "for i in range(784):\n",
    "    var_sum=var_sum+PCA_out.fracs[i]\n",
    "    if var_sum>0.99:\n",
    "        print(\"{}\".format(i))\n",
    "        break\n",
    "\n",
    "rd=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dr=pca.transform(PCA_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rd=X_train_dr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dr=X_train_dr.reshape((50000,1,rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_dr=pca.transform(PCA_in_test).reshape((10000,1,rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_dr=pca.transform(PCA_in_val).reshape((10000,1,rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network learning with DR examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from lasagne.regularization import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # By default, this creates the same network as `build_mlp`, but it can be\n",
    "    # customized with respect to the number and size of hidden layers. This\n",
    "    # mostly showcases how creating a network in Python code can be a lot more\n",
    "    # flexible than a configuration file. Note that to make the code easier,\n",
    "    # all the layers are just called `network` -- there is no need to give them\n",
    "    # different names if all we return is the last one we created anyway; we\n",
    "    # just used different names above for clarity.\n",
    "\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, rd),\n",
    "                                        input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 0.693s\n",
      "  training loss:\t\t1.149092\n",
      "  validation loss:\t\t0.590480\n",
      "  validation accuracy:\t\t84.77 %\n",
      "Epoch 2 of 500 took 0.682s\n",
      "  training loss:\t\t0.565115\n",
      "  validation loss:\t\t0.466210\n",
      "  validation accuracy:\t\t87.74 %\n",
      "Epoch 3 of 500 took 1.480s\n",
      "  training loss:\t\t0.482893\n",
      "  validation loss:\t\t0.418880\n",
      "  validation accuracy:\t\t88.71 %\n",
      "Epoch 4 of 500 took 0.863s\n",
      "  training loss:\t\t0.443773\n",
      "  validation loss:\t\t0.392911\n",
      "  validation accuracy:\t\t89.22 %\n",
      "Epoch 5 of 500 took 0.819s\n",
      "  training loss:\t\t0.419948\n",
      "  validation loss:\t\t0.375853\n",
      "  validation accuracy:\t\t89.63 %\n",
      "Epoch 6 of 500 took 0.821s\n",
      "  training loss:\t\t0.403467\n",
      "  validation loss:\t\t0.363864\n",
      "  validation accuracy:\t\t89.85 %\n",
      "Epoch 7 of 500 took 0.726s\n",
      "  training loss:\t\t0.391268\n",
      "  validation loss:\t\t0.354831\n",
      "  validation accuracy:\t\t90.26 %\n",
      "Epoch 8 of 500 took 1.287s\n",
      "  training loss:\t\t0.381745\n",
      "  validation loss:\t\t0.347651\n",
      "  validation accuracy:\t\t90.43 %\n",
      "Epoch 9 of 500 took 1.005s\n",
      "  training loss:\t\t0.374099\n",
      "  validation loss:\t\t0.341936\n",
      "  validation accuracy:\t\t90.52 %\n",
      "Epoch 10 of 500 took 1.249s\n",
      "  training loss:\t\t0.367744\n",
      "  validation loss:\t\t0.337062\n",
      "  validation accuracy:\t\t90.65 %\n",
      "Epoch 11 of 500 took 1.040s\n",
      "  training loss:\t\t0.362407\n",
      "  validation loss:\t\t0.332893\n",
      "  validation accuracy:\t\t90.68 %\n",
      "Epoch 12 of 500 took 0.860s\n",
      "  training loss:\t\t0.357755\n",
      "  validation loss:\t\t0.329228\n",
      "  validation accuracy:\t\t90.73 %\n",
      "Epoch 13 of 500 took 0.779s\n",
      "  training loss:\t\t0.353727\n",
      "  validation loss:\t\t0.326226\n",
      "  validation accuracy:\t\t90.81 %\n",
      "Epoch 14 of 500 took 0.751s\n",
      "  training loss:\t\t0.350173\n",
      "  validation loss:\t\t0.323332\n",
      "  validation accuracy:\t\t90.93 %\n",
      "Epoch 15 of 500 took 0.709s\n",
      "  training loss:\t\t0.347012\n",
      "  validation loss:\t\t0.320892\n",
      "  validation accuracy:\t\t90.98 %\n",
      "Epoch 16 of 500 took 0.696s\n",
      "  training loss:\t\t0.344207\n",
      "  validation loss:\t\t0.318647\n",
      "  validation accuracy:\t\t91.06 %\n",
      "Epoch 17 of 500 took 0.729s\n",
      "  training loss:\t\t0.341639\n",
      "  validation loss:\t\t0.316742\n",
      "  validation accuracy:\t\t91.07 %\n",
      "Epoch 18 of 500 took 0.716s\n",
      "  training loss:\t\t0.339317\n",
      "  validation loss:\t\t0.315018\n",
      "  validation accuracy:\t\t91.09 %\n",
      "Epoch 19 of 500 took 0.725s\n",
      "  training loss:\t\t0.337167\n",
      "  validation loss:\t\t0.313256\n",
      "  validation accuracy:\t\t91.19 %\n",
      "Epoch 20 of 500 took 0.746s\n",
      "  training loss:\t\t0.335226\n",
      "  validation loss:\t\t0.311714\n",
      "  validation accuracy:\t\t91.18 %\n",
      "Epoch 21 of 500 took 0.902s\n",
      "  training loss:\t\t0.333418\n",
      "  validation loss:\t\t0.310215\n",
      "  validation accuracy:\t\t91.24 %\n",
      "Epoch 22 of 500 took 0.814s\n",
      "  training loss:\t\t0.331775\n",
      "  validation loss:\t\t0.308903\n",
      "  validation accuracy:\t\t91.26 %\n",
      "Epoch 23 of 500 took 0.842s\n",
      "  training loss:\t\t0.330219\n",
      "  validation loss:\t\t0.307686\n",
      "  validation accuracy:\t\t91.29 %\n",
      "Epoch 24 of 500 took 0.718s\n",
      "  training loss:\t\t0.328800\n",
      "  validation loss:\t\t0.306647\n",
      "  validation accuracy:\t\t91.32 %\n",
      "Epoch 25 of 500 took 0.672s\n",
      "  training loss:\t\t0.327464\n",
      "  validation loss:\t\t0.305403\n",
      "  validation accuracy:\t\t91.40 %\n",
      "Epoch 26 of 500 took 1.022s\n",
      "  training loss:\t\t0.326195\n",
      "  validation loss:\t\t0.304566\n",
      "  validation accuracy:\t\t91.39 %\n",
      "Epoch 27 of 500 took 1.041s\n",
      "  training loss:\t\t0.325033\n",
      "  validation loss:\t\t0.303585\n",
      "  validation accuracy:\t\t91.44 %\n",
      "Epoch 28 of 500 took 0.811s\n",
      "  training loss:\t\t0.323910\n",
      "  validation loss:\t\t0.302699\n",
      "  validation accuracy:\t\t91.48 %\n",
      "Epoch 29 of 500 took 0.759s\n",
      "  training loss:\t\t0.322873\n",
      "  validation loss:\t\t0.301927\n",
      "  validation accuracy:\t\t91.47 %\n",
      "Epoch 30 of 500 took 0.729s\n",
      "  training loss:\t\t0.321883\n",
      "  validation loss:\t\t0.301216\n",
      "  validation accuracy:\t\t91.53 %\n",
      "Epoch 31 of 500 took 0.697s\n",
      "  training loss:\t\t0.320971\n",
      "  validation loss:\t\t0.300392\n",
      "  validation accuracy:\t\t91.59 %\n",
      "Epoch 32 of 500 took 0.752s\n",
      "  training loss:\t\t0.320106\n",
      "  validation loss:\t\t0.299720\n",
      "  validation accuracy:\t\t91.62 %\n",
      "Epoch 33 of 500 took 0.866s\n",
      "  training loss:\t\t0.319271\n",
      "  validation loss:\t\t0.298931\n",
      "  validation accuracy:\t\t91.62 %\n",
      "Epoch 34 of 500 took 1.133s\n",
      "  training loss:\t\t0.318440\n",
      "  validation loss:\t\t0.298406\n",
      "  validation accuracy:\t\t91.64 %\n",
      "Epoch 35 of 500 took 1.008s\n",
      "  training loss:\t\t0.317733\n",
      "  validation loss:\t\t0.297759\n",
      "  validation accuracy:\t\t91.61 %\n",
      "Epoch 36 of 500 took 1.216s\n",
      "  training loss:\t\t0.317029\n",
      "  validation loss:\t\t0.297224\n",
      "  validation accuracy:\t\t91.63 %\n",
      "Epoch 37 of 500 took 1.230s\n",
      "  training loss:\t\t0.316314\n",
      "  validation loss:\t\t0.296721\n",
      "  validation accuracy:\t\t91.64 %\n",
      "Epoch 38 of 500 took 1.354s\n",
      "  training loss:\t\t0.315654\n",
      "  validation loss:\t\t0.296085\n",
      "  validation accuracy:\t\t91.67 %\n",
      "Epoch 39 of 500 took 1.173s\n",
      "  training loss:\t\t0.315047\n",
      "  validation loss:\t\t0.295633\n",
      "  validation accuracy:\t\t91.72 %\n",
      "Epoch 40 of 500 took 1.027s\n",
      "  training loss:\t\t0.314397\n",
      "  validation loss:\t\t0.295163\n",
      "  validation accuracy:\t\t91.70 %\n",
      "Epoch 41 of 500 took 0.804s\n",
      "  training loss:\t\t0.313853\n",
      "  validation loss:\t\t0.294781\n",
      "  validation accuracy:\t\t91.73 %\n",
      "Epoch 42 of 500 took 0.907s\n",
      "  training loss:\t\t0.313267\n",
      "  validation loss:\t\t0.294230\n",
      "  validation accuracy:\t\t91.76 %\n",
      "Epoch 43 of 500 took 0.707s\n",
      "  training loss:\t\t0.312788\n",
      "  validation loss:\t\t0.293870\n",
      "  validation accuracy:\t\t91.76 %\n",
      "Epoch 44 of 500 took 1.062s\n",
      "  training loss:\t\t0.312283\n",
      "  validation loss:\t\t0.293411\n",
      "  validation accuracy:\t\t91.77 %\n",
      "Epoch 45 of 500 took 0.902s\n",
      "  training loss:\t\t0.311801\n",
      "  validation loss:\t\t0.293078\n",
      "  validation accuracy:\t\t91.79 %\n",
      "Epoch 46 of 500 took 0.745s\n",
      "  training loss:\t\t0.311364\n",
      "  validation loss:\t\t0.292736\n",
      "  validation accuracy:\t\t91.81 %\n",
      "Epoch 47 of 500 took 0.905s\n",
      "  training loss:\t\t0.310879\n",
      "  validation loss:\t\t0.292306\n",
      "  validation accuracy:\t\t91.82 %\n",
      "Epoch 48 of 500 took 1.377s\n",
      "  training loss:\t\t0.310447\n",
      "  validation loss:\t\t0.292004\n",
      "  validation accuracy:\t\t91.87 %\n",
      "Epoch 49 of 500 took 0.722s\n",
      "  training loss:\t\t0.310019\n",
      "  validation loss:\t\t0.291544\n",
      "  validation accuracy:\t\t91.86 %\n",
      "Epoch 50 of 500 took 0.706s\n",
      "  training loss:\t\t0.309632\n",
      "  validation loss:\t\t0.291256\n",
      "  validation accuracy:\t\t91.87 %\n",
      "Epoch 51 of 500 took 0.825s\n",
      "  training loss:\t\t0.309255\n",
      "  validation loss:\t\t0.290937\n",
      "  validation accuracy:\t\t91.90 %\n",
      "Epoch 52 of 500 took 0.710s\n",
      "  training loss:\t\t0.308868\n",
      "  validation loss:\t\t0.290747\n",
      "  validation accuracy:\t\t91.87 %\n",
      "Epoch 53 of 500 took 0.703s\n",
      "  training loss:\t\t0.308524\n",
      "  validation loss:\t\t0.290456\n",
      "  validation accuracy:\t\t91.91 %\n",
      "Epoch 54 of 500 took 0.710s\n",
      "  training loss:\t\t0.308141\n",
      "  validation loss:\t\t0.290202\n",
      "  validation accuracy:\t\t91.89 %\n",
      "Epoch 55 of 500 took 0.863s\n",
      "  training loss:\t\t0.307815\n",
      "  validation loss:\t\t0.289828\n",
      "  validation accuracy:\t\t91.90 %\n",
      "Epoch 56 of 500 took 1.326s\n",
      "  training loss:\t\t0.307514\n",
      "  validation loss:\t\t0.289583\n",
      "  validation accuracy:\t\t91.91 %\n",
      "Epoch 57 of 500 took 1.287s\n",
      "  training loss:\t\t0.307186\n",
      "  validation loss:\t\t0.289339\n",
      "  validation accuracy:\t\t91.90 %\n",
      "Epoch 58 of 500 took 1.151s\n",
      "  training loss:\t\t0.306884\n",
      "  validation loss:\t\t0.289094\n",
      "  validation accuracy:\t\t91.89 %\n",
      "Epoch 59 of 500 took 0.750s\n",
      "  training loss:\t\t0.306575\n",
      "  validation loss:\t\t0.288911\n",
      "  validation accuracy:\t\t91.88 %\n",
      "Epoch 60 of 500 took 0.752s\n",
      "  training loss:\t\t0.306287\n",
      "  validation loss:\t\t0.288721\n",
      "  validation accuracy:\t\t91.89 %\n",
      "Epoch 61 of 500 took 1.037s\n",
      "  training loss:\t\t0.306004\n",
      "  validation loss:\t\t0.288523\n",
      "  validation accuracy:\t\t91.89 %\n",
      "Epoch 62 of 500 took 0.805s\n",
      "  training loss:\t\t0.305732\n",
      "  validation loss:\t\t0.288218\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 63 of 500 took 1.075s\n",
      "  training loss:\t\t0.305460\n",
      "  validation loss:\t\t0.287966\n",
      "  validation accuracy:\t\t91.90 %\n",
      "Epoch 64 of 500 took 1.233s\n",
      "  training loss:\t\t0.305223\n",
      "  validation loss:\t\t0.287798\n",
      "  validation accuracy:\t\t91.91 %\n",
      "Epoch 65 of 500 took 1.027s\n",
      "  training loss:\t\t0.304967\n",
      "  validation loss:\t\t0.287599\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 66 of 500 took 1.763s\n",
      "  training loss:\t\t0.304714\n",
      "  validation loss:\t\t0.287537\n",
      "  validation accuracy:\t\t91.93 %\n",
      "Epoch 67 of 500 took 0.870s\n",
      "  training loss:\t\t0.304497\n",
      "  validation loss:\t\t0.287262\n",
      "  validation accuracy:\t\t91.90 %\n",
      "Epoch 68 of 500 took 0.760s\n",
      "  training loss:\t\t0.304282\n",
      "  validation loss:\t\t0.287069\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 69 of 500 took 0.772s\n",
      "  training loss:\t\t0.304054\n",
      "  validation loss:\t\t0.287003\n",
      "  validation accuracy:\t\t91.91 %\n",
      "Epoch 70 of 500 took 0.706s\n",
      "  training loss:\t\t0.303822\n",
      "  validation loss:\t\t0.286702\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 71 of 500 took 0.679s\n",
      "  training loss:\t\t0.303605\n",
      "  validation loss:\t\t0.286565\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 72 of 500 took 0.708s\n",
      "  training loss:\t\t0.303414\n",
      "  validation loss:\t\t0.286422\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 73 of 500 took 0.802s\n",
      "  training loss:\t\t0.303225\n",
      "  validation loss:\t\t0.286130\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 74 of 500 took 0.705s\n",
      "  training loss:\t\t0.303023\n",
      "  validation loss:\t\t0.285997\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 75 of 500 took 0.704s\n",
      "  training loss:\t\t0.302803\n",
      "  validation loss:\t\t0.285930\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 76 of 500 took 0.702s\n",
      "  training loss:\t\t0.302654\n",
      "  validation loss:\t\t0.285820\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 77 of 500 took 0.701s\n",
      "  training loss:\t\t0.302469\n",
      "  validation loss:\t\t0.285707\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 78 of 500 took 0.683s\n",
      "  training loss:\t\t0.302296\n",
      "  validation loss:\t\t0.285450\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 79 of 500 took 0.703s\n",
      "  training loss:\t\t0.302108\n",
      "  validation loss:\t\t0.285371\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 80 of 500 took 0.779s\n",
      "  training loss:\t\t0.301966\n",
      "  validation loss:\t\t0.285152\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 81 of 500 took 0.762s\n",
      "  training loss:\t\t0.301768\n",
      "  validation loss:\t\t0.285042\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 82 of 500 took 0.791s\n",
      "  training loss:\t\t0.301613\n",
      "  validation loss:\t\t0.284879\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 83 of 500 took 0.708s\n",
      "  training loss:\t\t0.301443\n",
      "  validation loss:\t\t0.284794\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 84 of 500 took 0.760s\n",
      "  training loss:\t\t0.301322\n",
      "  validation loss:\t\t0.284699\n",
      "  validation accuracy:\t\t91.99 %\n",
      "Epoch 85 of 500 took 1.061s\n",
      "  training loss:\t\t0.301168\n",
      "  validation loss:\t\t0.284609\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 86 of 500 took 0.805s\n",
      "  training loss:\t\t0.301014\n",
      "  validation loss:\t\t0.284529\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 87 of 500 took 0.836s\n",
      "  training loss:\t\t0.300877\n",
      "  validation loss:\t\t0.284481\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 88 of 500 took 0.732s\n",
      "  training loss:\t\t0.300742\n",
      "  validation loss:\t\t0.284289\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 89 of 500 took 0.682s\n",
      "  training loss:\t\t0.300591\n",
      "  validation loss:\t\t0.284179\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 90 of 500 took 0.680s\n",
      "  training loss:\t\t0.300450\n",
      "  validation loss:\t\t0.284043\n",
      "  validation accuracy:\t\t91.98 %\n",
      "Epoch 91 of 500 took 0.701s\n",
      "  training loss:\t\t0.300342\n",
      "  validation loss:\t\t0.283990\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 92 of 500 took 0.768s\n",
      "  training loss:\t\t0.300212\n",
      "  validation loss:\t\t0.283837\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 93 of 500 took 0.787s\n",
      "  training loss:\t\t0.300088\n",
      "  validation loss:\t\t0.283760\n",
      "  validation accuracy:\t\t91.98 %\n",
      "Epoch 94 of 500 took 0.767s\n",
      "  training loss:\t\t0.299958\n",
      "  validation loss:\t\t0.283740\n",
      "  validation accuracy:\t\t91.98 %\n",
      "Epoch 95 of 500 took 0.808s\n",
      "  training loss:\t\t0.299834\n",
      "  validation loss:\t\t0.283556\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 96 of 500 took 0.708s\n",
      "  training loss:\t\t0.299703\n",
      "  validation loss:\t\t0.283443\n",
      "  validation accuracy:\t\t91.94 %\n",
      "Epoch 97 of 500 took 0.768s\n",
      "  training loss:\t\t0.299589\n",
      "  validation loss:\t\t0.283361\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 98 of 500 took 0.747s\n",
      "  training loss:\t\t0.299480\n",
      "  validation loss:\t\t0.283294\n",
      "  validation accuracy:\t\t91.94 %\n",
      "Epoch 99 of 500 took 0.744s\n",
      "  training loss:\t\t0.299379\n",
      "  validation loss:\t\t0.283161\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 100 of 500 took 0.738s\n",
      "  training loss:\t\t0.299258\n",
      "  validation loss:\t\t0.283102\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 101 of 500 took 0.727s\n",
      "  training loss:\t\t0.299156\n",
      "  validation loss:\t\t0.282998\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 102 of 500 took 0.738s\n",
      "  training loss:\t\t0.299065\n",
      "  validation loss:\t\t0.282840\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 103 of 500 took 1.157s\n",
      "  training loss:\t\t0.298969\n",
      "  validation loss:\t\t0.282843\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 104 of 500 took 0.717s\n",
      "  training loss:\t\t0.298869\n",
      "  validation loss:\t\t0.282715\n",
      "  validation accuracy:\t\t91.94 %\n",
      "Epoch 105 of 500 took 0.730s\n",
      "  training loss:\t\t0.298763\n",
      "  validation loss:\t\t0.282736\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 106 of 500 took 0.743s\n",
      "  training loss:\t\t0.298647\n",
      "  validation loss:\t\t0.282525\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 107 of 500 took 0.729s\n",
      "  training loss:\t\t0.298580\n",
      "  validation loss:\t\t0.282492\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 108 of 500 took 0.736s\n",
      "  training loss:\t\t0.298472\n",
      "  validation loss:\t\t0.282508\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 109 of 500 took 0.802s\n",
      "  training loss:\t\t0.298398\n",
      "  validation loss:\t\t0.282481\n",
      "  validation accuracy:\t\t91.96 %\n",
      "Epoch 110 of 500 took 0.824s\n",
      "  training loss:\t\t0.298306\n",
      "  validation loss:\t\t0.282367\n",
      "  validation accuracy:\t\t91.99 %\n",
      "Epoch 111 of 500 took 0.737s\n",
      "  training loss:\t\t0.298182\n",
      "  validation loss:\t\t0.282242\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 112 of 500 took 0.730s\n",
      "  training loss:\t\t0.298107\n",
      "  validation loss:\t\t0.282152\n",
      "  validation accuracy:\t\t91.97 %\n",
      "Epoch 113 of 500 took 0.745s\n",
      "  training loss:\t\t0.298019\n",
      "  validation loss:\t\t0.282080\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 114 of 500 took 0.983s\n",
      "  training loss:\t\t0.297922\n",
      "  validation loss:\t\t0.282039\n",
      "  validation accuracy:\t\t91.99 %\n",
      "Epoch 115 of 500 took 0.721s\n",
      "  training loss:\t\t0.297858\n",
      "  validation loss:\t\t0.282010\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 116 of 500 took 0.736s\n",
      "  training loss:\t\t0.297767\n",
      "  validation loss:\t\t0.281910\n",
      "  validation accuracy:\t\t91.99 %\n",
      "Epoch 117 of 500 took 0.734s\n",
      "  training loss:\t\t0.297707\n",
      "  validation loss:\t\t0.281841\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 118 of 500 took 0.929s\n",
      "  training loss:\t\t0.297628\n",
      "  validation loss:\t\t0.281840\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 119 of 500 took 0.714s\n",
      "  training loss:\t\t0.297534\n",
      "  validation loss:\t\t0.281749\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 120 of 500 took 0.715s\n",
      "  training loss:\t\t0.297466\n",
      "  validation loss:\t\t0.281685\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 121 of 500 took 0.683s\n",
      "  training loss:\t\t0.297388\n",
      "  validation loss:\t\t0.281558\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 122 of 500 took 0.715s\n",
      "  training loss:\t\t0.297314\n",
      "  validation loss:\t\t0.281537\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 123 of 500 took 0.727s\n",
      "  training loss:\t\t0.297234\n",
      "  validation loss:\t\t0.281508\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 124 of 500 took 0.770s\n",
      "  training loss:\t\t0.297196\n",
      "  validation loss:\t\t0.281425\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 125 of 500 took 0.721s\n",
      "  training loss:\t\t0.297109\n",
      "  validation loss:\t\t0.281451\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 126 of 500 took 0.731s\n",
      "  training loss:\t\t0.297045\n",
      "  validation loss:\t\t0.281369\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 127 of 500 took 0.717s\n",
      "  training loss:\t\t0.296967\n",
      "  validation loss:\t\t0.281244\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 128 of 500 took 0.998s\n",
      "  training loss:\t\t0.296898\n",
      "  validation loss:\t\t0.281241\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 129 of 500 took 0.803s\n",
      "  training loss:\t\t0.296858\n",
      "  validation loss:\t\t0.281123\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 130 of 500 took 0.732s\n",
      "  training loss:\t\t0.296775\n",
      "  validation loss:\t\t0.281126\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 131 of 500 took 0.729s\n",
      "  training loss:\t\t0.296710\n",
      "  validation loss:\t\t0.281038\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 132 of 500 took 0.720s\n",
      "  training loss:\t\t0.296667\n",
      "  validation loss:\t\t0.281009\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 133 of 500 took 0.686s\n",
      "  training loss:\t\t0.296608\n",
      "  validation loss:\t\t0.280981\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 134 of 500 took 0.750s\n",
      "  training loss:\t\t0.296523\n",
      "  validation loss:\t\t0.280943\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 135 of 500 took 0.734s\n",
      "  training loss:\t\t0.296476\n",
      "  validation loss:\t\t0.280797\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 136 of 500 took 0.670s\n",
      "  training loss:\t\t0.296410\n",
      "  validation loss:\t\t0.280883\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 137 of 500 took 0.668s\n",
      "  training loss:\t\t0.296332\n",
      "  validation loss:\t\t0.280870\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 138 of 500 took 0.691s\n",
      "  training loss:\t\t0.296284\n",
      "  validation loss:\t\t0.280727\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 139 of 500 took 0.688s\n",
      "  training loss:\t\t0.296232\n",
      "  validation loss:\t\t0.280752\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 140 of 500 took 0.669s\n",
      "  training loss:\t\t0.296192\n",
      "  validation loss:\t\t0.280626\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 141 of 500 took 0.695s\n",
      "  training loss:\t\t0.296134\n",
      "  validation loss:\t\t0.280534\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 142 of 500 took 0.688s\n",
      "  training loss:\t\t0.296090\n",
      "  validation loss:\t\t0.280571\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 143 of 500 took 0.681s\n",
      "  training loss:\t\t0.296029\n",
      "  validation loss:\t\t0.280465\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 144 of 500 took 0.674s\n",
      "  training loss:\t\t0.295979\n",
      "  validation loss:\t\t0.280496\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 145 of 500 took 0.681s\n",
      "  training loss:\t\t0.295902\n",
      "  validation loss:\t\t0.280383\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 146 of 500 took 0.680s\n",
      "  training loss:\t\t0.295863\n",
      "  validation loss:\t\t0.280294\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 147 of 500 took 0.692s\n",
      "  training loss:\t\t0.295829\n",
      "  validation loss:\t\t0.280283\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 148 of 500 took 0.688s\n",
      "  training loss:\t\t0.295761\n",
      "  validation loss:\t\t0.280381\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 149 of 500 took 0.677s\n",
      "  training loss:\t\t0.295703\n",
      "  validation loss:\t\t0.280239\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 150 of 500 took 0.751s\n",
      "  training loss:\t\t0.295706\n",
      "  validation loss:\t\t0.280219\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 151 of 500 took 0.726s\n",
      "  training loss:\t\t0.295622\n",
      "  validation loss:\t\t0.280230\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 152 of 500 took 0.747s\n",
      "  training loss:\t\t0.295587\n",
      "  validation loss:\t\t0.280162\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 153 of 500 took 0.693s\n",
      "  training loss:\t\t0.295523\n",
      "  validation loss:\t\t0.280083\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 154 of 500 took 0.689s\n",
      "  training loss:\t\t0.295505\n",
      "  validation loss:\t\t0.280073\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 155 of 500 took 0.695s\n",
      "  training loss:\t\t0.295430\n",
      "  validation loss:\t\t0.279952\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 156 of 500 took 0.687s\n",
      "  training loss:\t\t0.295384\n",
      "  validation loss:\t\t0.279973\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 157 of 500 took 0.693s\n",
      "  training loss:\t\t0.295348\n",
      "  validation loss:\t\t0.280006\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 158 of 500 took 0.771s\n",
      "  training loss:\t\t0.295321\n",
      "  validation loss:\t\t0.279906\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 159 of 500 took 0.680s\n",
      "  training loss:\t\t0.295278\n",
      "  validation loss:\t\t0.279843\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 160 of 500 took 0.708s\n",
      "  training loss:\t\t0.295207\n",
      "  validation loss:\t\t0.279823\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 161 of 500 took 0.680s\n",
      "  training loss:\t\t0.295186\n",
      "  validation loss:\t\t0.279864\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 162 of 500 took 0.683s\n",
      "  training loss:\t\t0.295163\n",
      "  validation loss:\t\t0.279773\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 163 of 500 took 0.670s\n",
      "  training loss:\t\t0.295103\n",
      "  validation loss:\t\t0.279755\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 164 of 500 took 0.672s\n",
      "  training loss:\t\t0.295063\n",
      "  validation loss:\t\t0.279712\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 165 of 500 took 0.683s\n",
      "  training loss:\t\t0.295030\n",
      "  validation loss:\t\t0.279790\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 166 of 500 took 0.679s\n",
      "  training loss:\t\t0.294987\n",
      "  validation loss:\t\t0.279661\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 167 of 500 took 0.722s\n",
      "  training loss:\t\t0.294948\n",
      "  validation loss:\t\t0.279528\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 168 of 500 took 0.785s\n",
      "  training loss:\t\t0.294932\n",
      "  validation loss:\t\t0.279602\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 169 of 500 took 0.724s\n",
      "  training loss:\t\t0.294894\n",
      "  validation loss:\t\t0.279507\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 170 of 500 took 0.730s\n",
      "  training loss:\t\t0.294859\n",
      "  validation loss:\t\t0.279567\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 171 of 500 took 0.721s\n",
      "  training loss:\t\t0.294838\n",
      "  validation loss:\t\t0.279511\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 172 of 500 took 0.751s\n",
      "  training loss:\t\t0.294758\n",
      "  validation loss:\t\t0.279442\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 173 of 500 took 0.747s\n",
      "  training loss:\t\t0.294736\n",
      "  validation loss:\t\t0.279365\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 174 of 500 took 0.773s\n",
      "  training loss:\t\t0.294696\n",
      "  validation loss:\t\t0.279331\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 175 of 500 took 0.851s\n",
      "  training loss:\t\t0.294675\n",
      "  validation loss:\t\t0.279408\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 176 of 500 took 0.882s\n",
      "  training loss:\t\t0.294616\n",
      "  validation loss:\t\t0.279331\n",
      "  validation accuracy:\t\t92.01 %\n",
      "Epoch 177 of 500 took 0.771s\n",
      "  training loss:\t\t0.294603\n",
      "  validation loss:\t\t0.279274\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 178 of 500 took 0.891s\n",
      "  training loss:\t\t0.294561\n",
      "  validation loss:\t\t0.279357\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 179 of 500 took 0.843s\n",
      "  training loss:\t\t0.294531\n",
      "  validation loss:\t\t0.279385\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 180 of 500 took 0.706s\n",
      "  training loss:\t\t0.294490\n",
      "  validation loss:\t\t0.279347\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 181 of 500 took 0.706s\n",
      "  training loss:\t\t0.294444\n",
      "  validation loss:\t\t0.279176\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 182 of 500 took 0.806s\n",
      "  training loss:\t\t0.294440\n",
      "  validation loss:\t\t0.279215\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 183 of 500 took 0.736s\n",
      "  training loss:\t\t0.294406\n",
      "  validation loss:\t\t0.279220\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 184 of 500 took 0.707s\n",
      "  training loss:\t\t0.294377\n",
      "  validation loss:\t\t0.279074\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 185 of 500 took 0.742s\n",
      "  training loss:\t\t0.294321\n",
      "  validation loss:\t\t0.279045\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 186 of 500 took 0.758s\n",
      "  training loss:\t\t0.294320\n",
      "  validation loss:\t\t0.279054\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 187 of 500 took 0.709s\n",
      "  training loss:\t\t0.294273\n",
      "  validation loss:\t\t0.279104\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 188 of 500 took 0.687s\n",
      "  training loss:\t\t0.294247\n",
      "  validation loss:\t\t0.279043\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 189 of 500 took 0.681s\n",
      "  training loss:\t\t0.294230\n",
      "  validation loss:\t\t0.279095\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 190 of 500 took 0.681s\n",
      "  training loss:\t\t0.294159\n",
      "  validation loss:\t\t0.279033\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 191 of 500 took 0.706s\n",
      "  training loss:\t\t0.294143\n",
      "  validation loss:\t\t0.278975\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 192 of 500 took 0.896s\n",
      "  training loss:\t\t0.294122\n",
      "  validation loss:\t\t0.278983\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 193 of 500 took 0.799s\n",
      "  training loss:\t\t0.294112\n",
      "  validation loss:\t\t0.279072\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 194 of 500 took 1.306s\n",
      "  training loss:\t\t0.294078\n",
      "  validation loss:\t\t0.278928\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 195 of 500 took 0.962s\n",
      "  training loss:\t\t0.294056\n",
      "  validation loss:\t\t0.278910\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 196 of 500 took 0.777s\n",
      "  training loss:\t\t0.294034\n",
      "  validation loss:\t\t0.278867\n",
      "  validation accuracy:\t\t92.02 %\n",
      "Epoch 197 of 500 took 0.739s\n",
      "  training loss:\t\t0.293976\n",
      "  validation loss:\t\t0.278806\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 198 of 500 took 0.712s\n",
      "  training loss:\t\t0.293968\n",
      "  validation loss:\t\t0.278749\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 199 of 500 took 0.737s\n",
      "  training loss:\t\t0.293942\n",
      "  validation loss:\t\t0.278790\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 200 of 500 took 0.810s\n",
      "  training loss:\t\t0.293902\n",
      "  validation loss:\t\t0.278698\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 201 of 500 took 0.724s\n",
      "  training loss:\t\t0.293892\n",
      "  validation loss:\t\t0.278736\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 202 of 500 took 0.731s\n",
      "  training loss:\t\t0.293871\n",
      "  validation loss:\t\t0.278787\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 203 of 500 took 0.744s\n",
      "  training loss:\t\t0.293866\n",
      "  validation loss:\t\t0.278685\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 204 of 500 took 0.787s\n",
      "  training loss:\t\t0.293811\n",
      "  validation loss:\t\t0.278668\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 205 of 500 took 0.775s\n",
      "  training loss:\t\t0.293774\n",
      "  validation loss:\t\t0.278661\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 206 of 500 took 0.739s\n",
      "  training loss:\t\t0.293769\n",
      "  validation loss:\t\t0.278740\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 207 of 500 took 0.721s\n",
      "  training loss:\t\t0.293754\n",
      "  validation loss:\t\t0.278711\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 208 of 500 took 0.722s\n",
      "  training loss:\t\t0.293721\n",
      "  validation loss:\t\t0.278635\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 209 of 500 took 0.715s\n",
      "  training loss:\t\t0.293682\n",
      "  validation loss:\t\t0.278608\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 210 of 500 took 0.699s\n",
      "  training loss:\t\t0.293665\n",
      "  validation loss:\t\t0.278578\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 211 of 500 took 0.699s\n",
      "  training loss:\t\t0.293649\n",
      "  validation loss:\t\t0.278497\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 212 of 500 took 0.717s\n",
      "  training loss:\t\t0.293623\n",
      "  validation loss:\t\t0.278565\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 213 of 500 took 0.730s\n",
      "  training loss:\t\t0.293626\n",
      "  validation loss:\t\t0.278530\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 214 of 500 took 0.743s\n",
      "  training loss:\t\t0.293616\n",
      "  validation loss:\t\t0.278537\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 215 of 500 took 0.733s\n",
      "  training loss:\t\t0.293570\n",
      "  validation loss:\t\t0.278561\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 216 of 500 took 0.796s\n",
      "  training loss:\t\t0.293546\n",
      "  validation loss:\t\t0.278456\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 217 of 500 took 0.696s\n",
      "  training loss:\t\t0.293517\n",
      "  validation loss:\t\t0.278408\n",
      "  validation accuracy:\t\t92.05 %\n",
      "Epoch 218 of 500 took 0.764s\n",
      "  training loss:\t\t0.293478\n",
      "  validation loss:\t\t0.278449\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 219 of 500 took 0.787s\n",
      "  training loss:\t\t0.293455\n",
      "  validation loss:\t\t0.278439\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 220 of 500 took 0.732s\n",
      "  training loss:\t\t0.293435\n",
      "  validation loss:\t\t0.278351\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 221 of 500 took 0.809s\n",
      "  training loss:\t\t0.293426\n",
      "  validation loss:\t\t0.278279\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 222 of 500 took 0.703s\n",
      "  training loss:\t\t0.293392\n",
      "  validation loss:\t\t0.278323\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 223 of 500 took 0.701s\n",
      "  training loss:\t\t0.293372\n",
      "  validation loss:\t\t0.278299\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 224 of 500 took 0.719s\n",
      "  training loss:\t\t0.293375\n",
      "  validation loss:\t\t0.278336\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 225 of 500 took 0.693s\n",
      "  training loss:\t\t0.293343\n",
      "  validation loss:\t\t0.278352\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 226 of 500 took 0.703s\n",
      "  training loss:\t\t0.293344\n",
      "  validation loss:\t\t0.278268\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 227 of 500 took 0.697s\n",
      "  training loss:\t\t0.293305\n",
      "  validation loss:\t\t0.278235\n",
      "  validation accuracy:\t\t92.11 %\n",
      "Epoch 228 of 500 took 0.756s\n",
      "  training loss:\t\t0.293304\n",
      "  validation loss:\t\t0.278201\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 229 of 500 took 0.733s\n",
      "  training loss:\t\t0.293265\n",
      "  validation loss:\t\t0.278160\n",
      "  validation accuracy:\t\t92.11 %\n",
      "Epoch 230 of 500 took 0.698s\n",
      "  training loss:\t\t0.293248\n",
      "  validation loss:\t\t0.278241\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 231 of 500 took 0.764s\n",
      "  training loss:\t\t0.293215\n",
      "  validation loss:\t\t0.278174\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 232 of 500 took 0.707s\n",
      "  training loss:\t\t0.293207\n",
      "  validation loss:\t\t0.278263\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 233 of 500 took 0.724s\n",
      "  training loss:\t\t0.293187\n",
      "  validation loss:\t\t0.278178\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 234 of 500 took 0.759s\n",
      "  training loss:\t\t0.293191\n",
      "  validation loss:\t\t0.278116\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 235 of 500 took 0.706s\n",
      "  training loss:\t\t0.293161\n",
      "  validation loss:\t\t0.278143\n",
      "  validation accuracy:\t\t92.06 %\n",
      "Epoch 236 of 500 took 0.835s\n",
      "  training loss:\t\t0.293154\n",
      "  validation loss:\t\t0.278179\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 237 of 500 took 0.820s\n",
      "  training loss:\t\t0.293151\n",
      "  validation loss:\t\t0.278103\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 238 of 500 took 1.125s\n",
      "  training loss:\t\t0.293081\n",
      "  validation loss:\t\t0.278077\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 239 of 500 took 0.901s\n",
      "  training loss:\t\t0.293073\n",
      "  validation loss:\t\t0.277972\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 240 of 500 took 1.610s\n",
      "  training loss:\t\t0.293065\n",
      "  validation loss:\t\t0.278095\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 241 of 500 took 1.226s\n",
      "  training loss:\t\t0.293042\n",
      "  validation loss:\t\t0.277967\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Epoch 242 of 500 took 0.885s\n",
      "  training loss:\t\t0.293022\n",
      "  validation loss:\t\t0.278019\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 243 of 500 took 1.217s\n",
      "  training loss:\t\t0.293014\n",
      "  validation loss:\t\t0.277991\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 244 of 500 took 1.446s\n",
      "  training loss:\t\t0.292980\n",
      "  validation loss:\t\t0.277980\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 245 of 500 took 1.459s\n",
      "  training loss:\t\t0.292989\n",
      "  validation loss:\t\t0.278000\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 246 of 500 took 1.389s\n",
      "  training loss:\t\t0.292959\n",
      "  validation loss:\t\t0.277921\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 247 of 500 took 0.972s\n",
      "  training loss:\t\t0.292947\n",
      "  validation loss:\t\t0.277918\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 248 of 500 took 1.296s\n",
      "  training loss:\t\t0.292937\n",
      "  validation loss:\t\t0.277973\n",
      "  validation accuracy:\t\t92.11 %\n",
      "Epoch 249 of 500 took 0.847s\n",
      "  training loss:\t\t0.292929\n",
      "  validation loss:\t\t0.277917\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 250 of 500 took 1.134s\n",
      "  training loss:\t\t0.292920\n",
      "  validation loss:\t\t0.277916\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 251 of 500 took 0.880s\n",
      "  training loss:\t\t0.292888\n",
      "  validation loss:\t\t0.277849\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 252 of 500 took 0.804s\n",
      "  training loss:\t\t0.292874\n",
      "  validation loss:\t\t0.277910\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 253 of 500 took 0.701s\n",
      "  training loss:\t\t0.292840\n",
      "  validation loss:\t\t0.277845\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 254 of 500 took 0.687s\n",
      "  training loss:\t\t0.292822\n",
      "  validation loss:\t\t0.277936\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 255 of 500 took 0.708s\n",
      "  training loss:\t\t0.292797\n",
      "  validation loss:\t\t0.277819\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 256 of 500 took 0.724s\n",
      "  training loss:\t\t0.292800\n",
      "  validation loss:\t\t0.277768\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 257 of 500 took 0.790s\n",
      "  training loss:\t\t0.292821\n",
      "  validation loss:\t\t0.277865\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 258 of 500 took 0.684s\n",
      "  training loss:\t\t0.292783\n",
      "  validation loss:\t\t0.277808\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 259 of 500 took 0.678s\n",
      "  training loss:\t\t0.292784\n",
      "  validation loss:\t\t0.277732\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 260 of 500 took 0.690s\n",
      "  training loss:\t\t0.292743\n",
      "  validation loss:\t\t0.277789\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 261 of 500 took 0.694s\n",
      "  training loss:\t\t0.292743\n",
      "  validation loss:\t\t0.277816\n",
      "  validation accuracy:\t\t92.11 %\n",
      "Epoch 262 of 500 took 0.695s\n",
      "  training loss:\t\t0.292737\n",
      "  validation loss:\t\t0.277769\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 263 of 500 took 0.818s\n",
      "  training loss:\t\t0.292700\n",
      "  validation loss:\t\t0.277758\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 264 of 500 took 1.041s\n",
      "  training loss:\t\t0.292687\n",
      "  validation loss:\t\t0.277723\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 265 of 500 took 0.999s\n",
      "  training loss:\t\t0.292653\n",
      "  validation loss:\t\t0.277702\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 266 of 500 took 0.710s\n",
      "  training loss:\t\t0.292663\n",
      "  validation loss:\t\t0.277716\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 267 of 500 took 0.709s\n",
      "  training loss:\t\t0.292637\n",
      "  validation loss:\t\t0.277725\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 268 of 500 took 0.681s\n",
      "  training loss:\t\t0.292631\n",
      "  validation loss:\t\t0.277682\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 269 of 500 took 0.783s\n",
      "  training loss:\t\t0.292616\n",
      "  validation loss:\t\t0.277795\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 270 of 500 took 0.778s\n",
      "  training loss:\t\t0.292638\n",
      "  validation loss:\t\t0.277703\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 271 of 500 took 0.822s\n",
      "  training loss:\t\t0.292607\n",
      "  validation loss:\t\t0.277619\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 272 of 500 took 0.825s\n",
      "  training loss:\t\t0.292572\n",
      "  validation loss:\t\t0.277547\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 273 of 500 took 1.231s\n",
      "  training loss:\t\t0.292568\n",
      "  validation loss:\t\t0.277623\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 274 of 500 took 0.952s\n",
      "  training loss:\t\t0.292540\n",
      "  validation loss:\t\t0.277568\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 275 of 500 took 0.709s\n",
      "  training loss:\t\t0.292543\n",
      "  validation loss:\t\t0.277602\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 276 of 500 took 0.688s\n",
      "  training loss:\t\t0.292534\n",
      "  validation loss:\t\t0.277482\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 277 of 500 took 0.752s\n",
      "  training loss:\t\t0.292539\n",
      "  validation loss:\t\t0.277544\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 278 of 500 took 0.681s\n",
      "  training loss:\t\t0.292496\n",
      "  validation loss:\t\t0.277564\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 279 of 500 took 0.697s\n",
      "  training loss:\t\t0.292490\n",
      "  validation loss:\t\t0.277530\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 280 of 500 took 0.692s\n",
      "  training loss:\t\t0.292477\n",
      "  validation loss:\t\t0.277501\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 281 of 500 took 0.688s\n",
      "  training loss:\t\t0.292491\n",
      "  validation loss:\t\t0.277461\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 282 of 500 took 0.683s\n",
      "  training loss:\t\t0.292467\n",
      "  validation loss:\t\t0.277528\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 283 of 500 took 0.682s\n",
      "  training loss:\t\t0.292458\n",
      "  validation loss:\t\t0.277481\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 284 of 500 took 0.692s\n",
      "  training loss:\t\t0.292419\n",
      "  validation loss:\t\t0.277561\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 285 of 500 took 0.688s\n",
      "  training loss:\t\t0.292458\n",
      "  validation loss:\t\t0.277560\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 286 of 500 took 0.704s\n",
      "  training loss:\t\t0.292428\n",
      "  validation loss:\t\t0.277552\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 287 of 500 took 0.713s\n",
      "  training loss:\t\t0.292401\n",
      "  validation loss:\t\t0.277536\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 288 of 500 took 0.684s\n",
      "  training loss:\t\t0.292410\n",
      "  validation loss:\t\t0.277392\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 289 of 500 took 0.688s\n",
      "  training loss:\t\t0.292339\n",
      "  validation loss:\t\t0.277442\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 290 of 500 took 0.687s\n",
      "  training loss:\t\t0.292350\n",
      "  validation loss:\t\t0.277411\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 291 of 500 took 0.704s\n",
      "  training loss:\t\t0.292345\n",
      "  validation loss:\t\t0.277341\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 292 of 500 took 0.687s\n",
      "  training loss:\t\t0.292335\n",
      "  validation loss:\t\t0.277417\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 293 of 500 took 0.698s\n",
      "  training loss:\t\t0.292334\n",
      "  validation loss:\t\t0.277312\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 294 of 500 took 0.683s\n",
      "  training loss:\t\t0.292310\n",
      "  validation loss:\t\t0.277438\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 295 of 500 took 0.674s\n",
      "  training loss:\t\t0.292308\n",
      "  validation loss:\t\t0.277341\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 296 of 500 took 0.677s\n",
      "  training loss:\t\t0.292288\n",
      "  validation loss:\t\t0.277385\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 297 of 500 took 0.676s\n",
      "  training loss:\t\t0.292307\n",
      "  validation loss:\t\t0.277394\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 298 of 500 took 0.701s\n",
      "  training loss:\t\t0.292265\n",
      "  validation loss:\t\t0.277300\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 299 of 500 took 0.742s\n",
      "  training loss:\t\t0.292287\n",
      "  validation loss:\t\t0.277368\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 300 of 500 took 0.711s\n",
      "  training loss:\t\t0.292247\n",
      "  validation loss:\t\t0.277224\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 301 of 500 took 0.675s\n",
      "  training loss:\t\t0.292238\n",
      "  validation loss:\t\t0.277216\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 302 of 500 took 0.672s\n",
      "  training loss:\t\t0.292228\n",
      "  validation loss:\t\t0.277273\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 303 of 500 took 0.678s\n",
      "  training loss:\t\t0.292232\n",
      "  validation loss:\t\t0.277269\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 304 of 500 took 0.710s\n",
      "  training loss:\t\t0.292217\n",
      "  validation loss:\t\t0.277280\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 305 of 500 took 0.680s\n",
      "  training loss:\t\t0.292221\n",
      "  validation loss:\t\t0.277327\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 306 of 500 took 0.684s\n",
      "  training loss:\t\t0.292183\n",
      "  validation loss:\t\t0.277225\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 307 of 500 took 0.708s\n",
      "  training loss:\t\t0.292183\n",
      "  validation loss:\t\t0.277293\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 308 of 500 took 0.688s\n",
      "  training loss:\t\t0.292165\n",
      "  validation loss:\t\t0.277151\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 309 of 500 took 0.685s\n",
      "  training loss:\t\t0.292168\n",
      "  validation loss:\t\t0.277185\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 310 of 500 took 0.678s\n",
      "  training loss:\t\t0.292131\n",
      "  validation loss:\t\t0.277244\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 311 of 500 took 0.680s\n",
      "  training loss:\t\t0.292144\n",
      "  validation loss:\t\t0.277151\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 312 of 500 took 0.678s\n",
      "  training loss:\t\t0.292128\n",
      "  validation loss:\t\t0.277204\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 313 of 500 took 0.690s\n",
      "  training loss:\t\t0.292128\n",
      "  validation loss:\t\t0.277151\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 314 of 500 took 0.690s\n",
      "  training loss:\t\t0.292121\n",
      "  validation loss:\t\t0.277231\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 315 of 500 took 0.684s\n",
      "  training loss:\t\t0.292095\n",
      "  validation loss:\t\t0.277220\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 316 of 500 took 0.684s\n",
      "  training loss:\t\t0.292106\n",
      "  validation loss:\t\t0.277206\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 317 of 500 took 0.681s\n",
      "  training loss:\t\t0.292089\n",
      "  validation loss:\t\t0.277256\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 318 of 500 took 0.685s\n",
      "  training loss:\t\t0.292077\n",
      "  validation loss:\t\t0.277189\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 319 of 500 took 0.714s\n",
      "  training loss:\t\t0.292063\n",
      "  validation loss:\t\t0.277077\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 320 of 500 took 0.714s\n",
      "  training loss:\t\t0.292074\n",
      "  validation loss:\t\t0.277085\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 321 of 500 took 0.779s\n",
      "  training loss:\t\t0.292038\n",
      "  validation loss:\t\t0.277037\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 322 of 500 took 0.775s\n",
      "  training loss:\t\t0.292042\n",
      "  validation loss:\t\t0.277043\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 323 of 500 took 0.685s\n",
      "  training loss:\t\t0.292027\n",
      "  validation loss:\t\t0.277000\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 324 of 500 took 0.682s\n",
      "  training loss:\t\t0.292020\n",
      "  validation loss:\t\t0.277030\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 325 of 500 took 0.670s\n",
      "  training loss:\t\t0.292032\n",
      "  validation loss:\t\t0.277036\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 326 of 500 took 0.676s\n",
      "  training loss:\t\t0.291998\n",
      "  validation loss:\t\t0.277008\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 327 of 500 took 0.690s\n",
      "  training loss:\t\t0.292000\n",
      "  validation loss:\t\t0.277087\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 328 of 500 took 0.687s\n",
      "  training loss:\t\t0.291988\n",
      "  validation loss:\t\t0.277053\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 329 of 500 took 0.714s\n",
      "  training loss:\t\t0.291972\n",
      "  validation loss:\t\t0.277034\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 330 of 500 took 0.683s\n",
      "  training loss:\t\t0.291962\n",
      "  validation loss:\t\t0.276986\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 331 of 500 took 0.688s\n",
      "  training loss:\t\t0.291966\n",
      "  validation loss:\t\t0.277080\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 332 of 500 took 0.673s\n",
      "  training loss:\t\t0.291937\n",
      "  validation loss:\t\t0.277026\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 333 of 500 took 0.688s\n",
      "  training loss:\t\t0.291958\n",
      "  validation loss:\t\t0.277000\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 334 of 500 took 0.677s\n",
      "  training loss:\t\t0.291940\n",
      "  validation loss:\t\t0.277053\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 335 of 500 took 0.675s\n",
      "  training loss:\t\t0.291926\n",
      "  validation loss:\t\t0.277065\n",
      "  validation accuracy:\t\t92.11 %\n",
      "Epoch 336 of 500 took 0.690s\n",
      "  training loss:\t\t0.291955\n",
      "  validation loss:\t\t0.276980\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 337 of 500 took 0.701s\n",
      "  training loss:\t\t0.291930\n",
      "  validation loss:\t\t0.276945\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 338 of 500 took 0.692s\n",
      "  training loss:\t\t0.291894\n",
      "  validation loss:\t\t0.277003\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 339 of 500 took 0.681s\n",
      "  training loss:\t\t0.291886\n",
      "  validation loss:\t\t0.277001\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 340 of 500 took 0.688s\n",
      "  training loss:\t\t0.291888\n",
      "  validation loss:\t\t0.276856\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 341 of 500 took 0.677s\n",
      "  training loss:\t\t0.291870\n",
      "  validation loss:\t\t0.276937\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 342 of 500 took 0.684s\n",
      "  training loss:\t\t0.291853\n",
      "  validation loss:\t\t0.276972\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 343 of 500 took 0.684s\n",
      "  training loss:\t\t0.291884\n",
      "  validation loss:\t\t0.277018\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 344 of 500 took 0.772s\n",
      "  training loss:\t\t0.291860\n",
      "  validation loss:\t\t0.277015\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 345 of 500 took 0.706s\n",
      "  training loss:\t\t0.291867\n",
      "  validation loss:\t\t0.276966\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 346 of 500 took 0.682s\n",
      "  training loss:\t\t0.291875\n",
      "  validation loss:\t\t0.276976\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 347 of 500 took 0.708s\n",
      "  training loss:\t\t0.291845\n",
      "  validation loss:\t\t0.276933\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 348 of 500 took 0.673s\n",
      "  training loss:\t\t0.291826\n",
      "  validation loss:\t\t0.276969\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 349 of 500 took 0.687s\n",
      "  training loss:\t\t0.291820\n",
      "  validation loss:\t\t0.276908\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 350 of 500 took 0.667s\n",
      "  training loss:\t\t0.291820\n",
      "  validation loss:\t\t0.276889\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 351 of 500 took 0.705s\n",
      "  training loss:\t\t0.291805\n",
      "  validation loss:\t\t0.276919\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 352 of 500 took 0.673s\n",
      "  training loss:\t\t0.291809\n",
      "  validation loss:\t\t0.276893\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 353 of 500 took 0.674s\n",
      "  training loss:\t\t0.291787\n",
      "  validation loss:\t\t0.276875\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 354 of 500 took 0.679s\n",
      "  training loss:\t\t0.291776\n",
      "  validation loss:\t\t0.276824\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 355 of 500 took 0.731s\n",
      "  training loss:\t\t0.291780\n",
      "  validation loss:\t\t0.276895\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 356 of 500 took 0.785s\n",
      "  training loss:\t\t0.291756\n",
      "  validation loss:\t\t0.276810\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 357 of 500 took 0.773s\n",
      "  training loss:\t\t0.291756\n",
      "  validation loss:\t\t0.276854\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 358 of 500 took 0.825s\n",
      "  training loss:\t\t0.291780\n",
      "  validation loss:\t\t0.276828\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 359 of 500 took 0.809s\n",
      "  training loss:\t\t0.291761\n",
      "  validation loss:\t\t0.276845\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 360 of 500 took 1.079s\n",
      "  training loss:\t\t0.291729\n",
      "  validation loss:\t\t0.276846\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 361 of 500 took 0.723s\n",
      "  training loss:\t\t0.291734\n",
      "  validation loss:\t\t0.276791\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 362 of 500 took 0.885s\n",
      "  training loss:\t\t0.291725\n",
      "  validation loss:\t\t0.276772\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 363 of 500 took 0.720s\n",
      "  training loss:\t\t0.291753\n",
      "  validation loss:\t\t0.276839\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 364 of 500 took 0.690s\n",
      "  training loss:\t\t0.291706\n",
      "  validation loss:\t\t0.276825\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 365 of 500 took 0.762s\n",
      "  training loss:\t\t0.291734\n",
      "  validation loss:\t\t0.276838\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 366 of 500 took 1.233s\n",
      "  training loss:\t\t0.291704\n",
      "  validation loss:\t\t0.276859\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 367 of 500 took 0.924s\n",
      "  training loss:\t\t0.291695\n",
      "  validation loss:\t\t0.276653\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 368 of 500 took 0.981s\n",
      "  training loss:\t\t0.291692\n",
      "  validation loss:\t\t0.276812\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 369 of 500 took 0.964s\n",
      "  training loss:\t\t0.291691\n",
      "  validation loss:\t\t0.276834\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 370 of 500 took 0.720s\n",
      "  training loss:\t\t0.291672\n",
      "  validation loss:\t\t0.276834\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 371 of 500 took 0.746s\n",
      "  training loss:\t\t0.291674\n",
      "  validation loss:\t\t0.276701\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 372 of 500 took 0.752s\n",
      "  training loss:\t\t0.291670\n",
      "  validation loss:\t\t0.276703\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 373 of 500 took 0.865s\n",
      "  training loss:\t\t0.291657\n",
      "  validation loss:\t\t0.276658\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 374 of 500 took 1.201s\n",
      "  training loss:\t\t0.291679\n",
      "  validation loss:\t\t0.276656\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 375 of 500 took 0.951s\n",
      "  training loss:\t\t0.291651\n",
      "  validation loss:\t\t0.276790\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 376 of 500 took 1.064s\n",
      "  training loss:\t\t0.291639\n",
      "  validation loss:\t\t0.276646\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 377 of 500 took 0.699s\n",
      "  training loss:\t\t0.291630\n",
      "  validation loss:\t\t0.276649\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 378 of 500 took 0.697s\n",
      "  training loss:\t\t0.291645\n",
      "  validation loss:\t\t0.276645\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 379 of 500 took 0.721s\n",
      "  training loss:\t\t0.291612\n",
      "  validation loss:\t\t0.276643\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 380 of 500 took 0.818s\n",
      "  training loss:\t\t0.291627\n",
      "  validation loss:\t\t0.276730\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 381 of 500 took 0.735s\n",
      "  training loss:\t\t0.291609\n",
      "  validation loss:\t\t0.276671\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 382 of 500 took 0.764s\n",
      "  training loss:\t\t0.291600\n",
      "  validation loss:\t\t0.276611\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 383 of 500 took 0.825s\n",
      "  training loss:\t\t0.291582\n",
      "  validation loss:\t\t0.276770\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 384 of 500 took 1.093s\n",
      "  training loss:\t\t0.291583\n",
      "  validation loss:\t\t0.276586\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 385 of 500 took 0.707s\n",
      "  training loss:\t\t0.291582\n",
      "  validation loss:\t\t0.276667\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 386 of 500 took 0.681s\n",
      "  training loss:\t\t0.291578\n",
      "  validation loss:\t\t0.276663\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 387 of 500 took 0.686s\n",
      "  training loss:\t\t0.291579\n",
      "  validation loss:\t\t0.276637\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 388 of 500 took 0.700s\n",
      "  training loss:\t\t0.291576\n",
      "  validation loss:\t\t0.276648\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 389 of 500 took 0.703s\n",
      "  training loss:\t\t0.291574\n",
      "  validation loss:\t\t0.276660\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 390 of 500 took 0.673s\n",
      "  training loss:\t\t0.291586\n",
      "  validation loss:\t\t0.276661\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 391 of 500 took 0.684s\n",
      "  training loss:\t\t0.291539\n",
      "  validation loss:\t\t0.276638\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 392 of 500 took 0.680s\n",
      "  training loss:\t\t0.291563\n",
      "  validation loss:\t\t0.276632\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 393 of 500 took 0.673s\n",
      "  training loss:\t\t0.291541\n",
      "  validation loss:\t\t0.276706\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 394 of 500 took 0.684s\n",
      "  training loss:\t\t0.291563\n",
      "  validation loss:\t\t0.276659\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 395 of 500 took 0.721s\n",
      "  training loss:\t\t0.291538\n",
      "  validation loss:\t\t0.276632\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 396 of 500 took 0.717s\n",
      "  training loss:\t\t0.291546\n",
      "  validation loss:\t\t0.276588\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 397 of 500 took 0.834s\n",
      "  training loss:\t\t0.291540\n",
      "  validation loss:\t\t0.276616\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 398 of 500 took 0.769s\n",
      "  training loss:\t\t0.291493\n",
      "  validation loss:\t\t0.276653\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 399 of 500 took 0.839s\n",
      "  training loss:\t\t0.291520\n",
      "  validation loss:\t\t0.276601\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 400 of 500 took 0.794s\n",
      "  training loss:\t\t0.291503\n",
      "  validation loss:\t\t0.276559\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 401 of 500 took 0.744s\n",
      "  training loss:\t\t0.291500\n",
      "  validation loss:\t\t0.276543\n",
      "  validation accuracy:\t\t92.21 %\n",
      "Epoch 402 of 500 took 0.773s\n",
      "  training loss:\t\t0.291495\n",
      "  validation loss:\t\t0.276569\n",
      "  validation accuracy:\t\t92.13 %\n",
      "Epoch 403 of 500 took 0.858s\n",
      "  training loss:\t\t0.291496\n",
      "  validation loss:\t\t0.276556\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 404 of 500 took 0.731s\n",
      "  training loss:\t\t0.291470\n",
      "  validation loss:\t\t0.276573\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 405 of 500 took 0.752s\n",
      "  training loss:\t\t0.291477\n",
      "  validation loss:\t\t0.276521\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 406 of 500 took 0.852s\n",
      "  training loss:\t\t0.291491\n",
      "  validation loss:\t\t0.276612\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 407 of 500 took 0.683s\n",
      "  training loss:\t\t0.291486\n",
      "  validation loss:\t\t0.276608\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 408 of 500 took 0.680s\n",
      "  training loss:\t\t0.291460\n",
      "  validation loss:\t\t0.276561\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 409 of 500 took 0.680s\n",
      "  training loss:\t\t0.291475\n",
      "  validation loss:\t\t0.276532\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 410 of 500 took 0.695s\n",
      "  training loss:\t\t0.291470\n",
      "  validation loss:\t\t0.276545\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 411 of 500 took 0.680s\n",
      "  training loss:\t\t0.291443\n",
      "  validation loss:\t\t0.276491\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 412 of 500 took 0.687s\n",
      "  training loss:\t\t0.291448\n",
      "  validation loss:\t\t0.276561\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 413 of 500 took 0.685s\n",
      "  training loss:\t\t0.291425\n",
      "  validation loss:\t\t0.276541\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 414 of 500 took 0.672s\n",
      "  training loss:\t\t0.291455\n",
      "  validation loss:\t\t0.276409\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 415 of 500 took 0.844s\n",
      "  training loss:\t\t0.291452\n",
      "  validation loss:\t\t0.276453\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 416 of 500 took 0.718s\n",
      "  training loss:\t\t0.291399\n",
      "  validation loss:\t\t0.276463\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 417 of 500 took 0.705s\n",
      "  training loss:\t\t0.291397\n",
      "  validation loss:\t\t0.276540\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 418 of 500 took 0.702s\n",
      "  training loss:\t\t0.291426\n",
      "  validation loss:\t\t0.276474\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 419 of 500 took 0.711s\n",
      "  training loss:\t\t0.291396\n",
      "  validation loss:\t\t0.276500\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 420 of 500 took 0.703s\n",
      "  training loss:\t\t0.291400\n",
      "  validation loss:\t\t0.276518\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 421 of 500 took 0.729s\n",
      "  training loss:\t\t0.291413\n",
      "  validation loss:\t\t0.276445\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 422 of 500 took 0.772s\n",
      "  training loss:\t\t0.291384\n",
      "  validation loss:\t\t0.276419\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 423 of 500 took 0.775s\n",
      "  training loss:\t\t0.291373\n",
      "  validation loss:\t\t0.276550\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 424 of 500 took 0.717s\n",
      "  training loss:\t\t0.291349\n",
      "  validation loss:\t\t0.276491\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 425 of 500 took 0.741s\n",
      "  training loss:\t\t0.291379\n",
      "  validation loss:\t\t0.276395\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 426 of 500 took 0.759s\n",
      "  training loss:\t\t0.291382\n",
      "  validation loss:\t\t0.276468\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 427 of 500 took 0.763s\n",
      "  training loss:\t\t0.291356\n",
      "  validation loss:\t\t0.276480\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 428 of 500 took 1.203s\n",
      "  training loss:\t\t0.291376\n",
      "  validation loss:\t\t0.276429\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 429 of 500 took 1.004s\n",
      "  training loss:\t\t0.291381\n",
      "  validation loss:\t\t0.276405\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 430 of 500 took 1.006s\n",
      "  training loss:\t\t0.291369\n",
      "  validation loss:\t\t0.276387\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 431 of 500 took 1.407s\n",
      "  training loss:\t\t0.291357\n",
      "  validation loss:\t\t0.276408\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 432 of 500 took 0.729s\n",
      "  training loss:\t\t0.291366\n",
      "  validation loss:\t\t0.276399\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 433 of 500 took 0.738s\n",
      "  training loss:\t\t0.291338\n",
      "  validation loss:\t\t0.276451\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 434 of 500 took 0.712s\n",
      "  training loss:\t\t0.291341\n",
      "  validation loss:\t\t0.276488\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 435 of 500 took 0.707s\n",
      "  training loss:\t\t0.291338\n",
      "  validation loss:\t\t0.276495\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 436 of 500 took 0.732s\n",
      "  training loss:\t\t0.291320\n",
      "  validation loss:\t\t0.276485\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 437 of 500 took 0.700s\n",
      "  training loss:\t\t0.291350\n",
      "  validation loss:\t\t0.276404\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 438 of 500 took 0.709s\n",
      "  training loss:\t\t0.291337\n",
      "  validation loss:\t\t0.276409\n",
      "  validation accuracy:\t\t92.21 %\n",
      "Epoch 439 of 500 took 0.714s\n",
      "  training loss:\t\t0.291341\n",
      "  validation loss:\t\t0.276460\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 440 of 500 took 0.909s\n",
      "  training loss:\t\t0.291280\n",
      "  validation loss:\t\t0.276455\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 441 of 500 took 0.806s\n",
      "  training loss:\t\t0.291321\n",
      "  validation loss:\t\t0.276412\n",
      "  validation accuracy:\t\t92.21 %\n",
      "Epoch 442 of 500 took 0.688s\n",
      "  training loss:\t\t0.291325\n",
      "  validation loss:\t\t0.276397\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 443 of 500 took 0.926s\n",
      "  training loss:\t\t0.291308\n",
      "  validation loss:\t\t0.276344\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 444 of 500 took 0.748s\n",
      "  training loss:\t\t0.291309\n",
      "  validation loss:\t\t0.276285\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 445 of 500 took 0.693s\n",
      "  training loss:\t\t0.291291\n",
      "  validation loss:\t\t0.276391\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 446 of 500 took 0.697s\n",
      "  training loss:\t\t0.291300\n",
      "  validation loss:\t\t0.276405\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 447 of 500 took 0.845s\n",
      "  training loss:\t\t0.291286\n",
      "  validation loss:\t\t0.276332\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 448 of 500 took 0.798s\n",
      "  training loss:\t\t0.291273\n",
      "  validation loss:\t\t0.276335\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 449 of 500 took 0.887s\n",
      "  training loss:\t\t0.291262\n",
      "  validation loss:\t\t0.276392\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 450 of 500 took 0.712s\n",
      "  training loss:\t\t0.291266\n",
      "  validation loss:\t\t0.276340\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 451 of 500 took 0.703s\n",
      "  training loss:\t\t0.291259\n",
      "  validation loss:\t\t0.276308\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 452 of 500 took 0.731s\n",
      "  training loss:\t\t0.291256\n",
      "  validation loss:\t\t0.276330\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 453 of 500 took 0.903s\n",
      "  training loss:\t\t0.291253\n",
      "  validation loss:\t\t0.276331\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 454 of 500 took 0.691s\n",
      "  training loss:\t\t0.291272\n",
      "  validation loss:\t\t0.276336\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 455 of 500 took 0.881s\n",
      "  training loss:\t\t0.291263\n",
      "  validation loss:\t\t0.276371\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 456 of 500 took 0.952s\n",
      "  training loss:\t\t0.291258\n",
      "  validation loss:\t\t0.276269\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 457 of 500 took 0.679s\n",
      "  training loss:\t\t0.291234\n",
      "  validation loss:\t\t0.276346\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 458 of 500 took 0.713s\n",
      "  training loss:\t\t0.291242\n",
      "  validation loss:\t\t0.276398\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 459 of 500 took 0.691s\n",
      "  training loss:\t\t0.291250\n",
      "  validation loss:\t\t0.276359\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 460 of 500 took 0.754s\n",
      "  training loss:\t\t0.291242\n",
      "  validation loss:\t\t0.276369\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 461 of 500 took 0.922s\n",
      "  training loss:\t\t0.291208\n",
      "  validation loss:\t\t0.276431\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 462 of 500 took 1.035s\n",
      "  training loss:\t\t0.291213\n",
      "  validation loss:\t\t0.276265\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 463 of 500 took 1.123s\n",
      "  training loss:\t\t0.291239\n",
      "  validation loss:\t\t0.276385\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 464 of 500 took 0.958s\n",
      "  training loss:\t\t0.291239\n",
      "  validation loss:\t\t0.276373\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 465 of 500 took 0.815s\n",
      "  training loss:\t\t0.291222\n",
      "  validation loss:\t\t0.276312\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 466 of 500 took 1.051s\n",
      "  training loss:\t\t0.291227\n",
      "  validation loss:\t\t0.276309\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 467 of 500 took 0.918s\n",
      "  training loss:\t\t0.291208\n",
      "  validation loss:\t\t0.276317\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 468 of 500 took 0.845s\n",
      "  training loss:\t\t0.291203\n",
      "  validation loss:\t\t0.276331\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 469 of 500 took 0.737s\n",
      "  training loss:\t\t0.291191\n",
      "  validation loss:\t\t0.276295\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 470 of 500 took 0.710s\n",
      "  training loss:\t\t0.291193\n",
      "  validation loss:\t\t0.276326\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 471 of 500 took 0.830s\n",
      "  training loss:\t\t0.291199\n",
      "  validation loss:\t\t0.276253\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 472 of 500 took 1.049s\n",
      "  training loss:\t\t0.291181\n",
      "  validation loss:\t\t0.276177\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 473 of 500 took 0.825s\n",
      "  training loss:\t\t0.291196\n",
      "  validation loss:\t\t0.276266\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 474 of 500 took 0.855s\n",
      "  training loss:\t\t0.291193\n",
      "  validation loss:\t\t0.276245\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 475 of 500 took 0.787s\n",
      "  training loss:\t\t0.291170\n",
      "  validation loss:\t\t0.276277\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 476 of 500 took 0.778s\n",
      "  training loss:\t\t0.291186\n",
      "  validation loss:\t\t0.276214\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 477 of 500 took 0.800s\n",
      "  training loss:\t\t0.291175\n",
      "  validation loss:\t\t0.276314\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 478 of 500 took 0.763s\n",
      "  training loss:\t\t0.291173\n",
      "  validation loss:\t\t0.276367\n",
      "  validation accuracy:\t\t92.22 %\n",
      "Epoch 479 of 500 took 0.856s\n",
      "  training loss:\t\t0.291153\n",
      "  validation loss:\t\t0.276239\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 480 of 500 took 0.831s\n",
      "  training loss:\t\t0.291188\n",
      "  validation loss:\t\t0.276270\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 481 of 500 took 0.800s\n",
      "  training loss:\t\t0.291155\n",
      "  validation loss:\t\t0.276314\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 482 of 500 took 0.768s\n",
      "  training loss:\t\t0.291155\n",
      "  validation loss:\t\t0.276273\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 483 of 500 took 0.770s\n",
      "  training loss:\t\t0.291150\n",
      "  validation loss:\t\t0.276223\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 484 of 500 took 0.756s\n",
      "  training loss:\t\t0.291153\n",
      "  validation loss:\t\t0.276208\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 485 of 500 took 0.801s\n",
      "  training loss:\t\t0.291154\n",
      "  validation loss:\t\t0.276275\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 486 of 500 took 0.901s\n",
      "  training loss:\t\t0.291153\n",
      "  validation loss:\t\t0.276250\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 487 of 500 took 0.749s\n",
      "  training loss:\t\t0.291146\n",
      "  validation loss:\t\t0.276183\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 488 of 500 took 0.748s\n",
      "  training loss:\t\t0.291147\n",
      "  validation loss:\t\t0.276242\n",
      "  validation accuracy:\t\t92.21 %\n",
      "Epoch 489 of 500 took 0.742s\n",
      "  training loss:\t\t0.291173\n",
      "  validation loss:\t\t0.276165\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 490 of 500 took 0.866s\n",
      "  training loss:\t\t0.291147\n",
      "  validation loss:\t\t0.276239\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 491 of 500 took 0.900s\n",
      "  training loss:\t\t0.291150\n",
      "  validation loss:\t\t0.276207\n",
      "  validation accuracy:\t\t92.22 %\n",
      "Epoch 492 of 500 took 0.944s\n",
      "  training loss:\t\t0.291131\n",
      "  validation loss:\t\t0.276171\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 493 of 500 took 0.702s\n",
      "  training loss:\t\t0.291124\n",
      "  validation loss:\t\t0.276148\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 494 of 500 took 0.696s\n",
      "  training loss:\t\t0.291116\n",
      "  validation loss:\t\t0.276171\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 495 of 500 took 0.704s\n",
      "  training loss:\t\t0.291109\n",
      "  validation loss:\t\t0.276180\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 496 of 500 took 0.769s\n",
      "  training loss:\t\t0.291083\n",
      "  validation loss:\t\t0.276175\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 497 of 500 took 0.759s\n",
      "  training loss:\t\t0.291109\n",
      "  validation loss:\t\t0.276142\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 498 of 500 took 1.211s\n",
      "  training loss:\t\t0.291087\n",
      "  validation loss:\t\t0.276145\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Epoch 499 of 500 took 0.825s\n",
      "  training loss:\t\t0.291097\n",
      "  validation loss:\t\t0.276181\n",
      "  validation accuracy:\t\t92.21 %\n",
      "Epoch 500 of 500 took 0.905s\n",
      "  training loss:\t\t0.291102\n",
      "  validation loss:\t\t0.276192\n",
      "  validation accuracy:\t\t92.19 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.284764\n",
      "  test accuracy:\t\t91.98 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "#X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model (depending on first command line parameter)\n",
    "print(\"Building model and compiling functions...\")\n",
    "\n",
    "num_epochs=500\n",
    "\n",
    "depth=0 \n",
    "width=0\n",
    "drop_in=0 \n",
    "drop_hid=0\n",
    "network = build_custom_mlp(input_var, int(depth), int(width), float(drop_in), float(drop_hid))\n",
    "\n",
    "\n",
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "l2_penalty=lasagne.regularization.regularize_layer_params(network,l2)*1\n",
    "loss=loss+l2_penalty/10\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "eval_fn=theano.function([input_var,target_var],loss)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "predict_fn=theano.function([input_var],T.argmax(test_prediction, axis=1))\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train_dr, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val_dr, y_val, 1, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    #print(\"{}\".format(inputs))\n",
    "    #print(\"{}\".format(targets+1))\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "#After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test_dr, y_test, 500, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "\n",
    "# Optionally, you could now dump the network weights to a file like this:\n",
    "# np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "#\n",
    "# And load them again later on like this:\n",
    "# with np.load('model.npz') as f:\n",
    "#     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "# lasagne.layers.set_all_param_values(network, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class is [7]\n",
      "Actual class is [4]\n",
      "Actual class is [0]\n",
      "Actual class is [2]\n",
      "Actual class is [0]\n",
      "Actual class is [1]\n",
      "Actual class is [4]\n",
      "Actual class is [7]\n",
      "Actual class is [2]\n",
      "Actual class is [3]\n",
      "% of misclassified examples is 100.0\n",
      "Deviation is 0.93695747065\n"
     ]
    }
   ],
   "source": [
    "outer_loop=np.random.randint(0,10000,10)\n",
    "count_wrong=0.0\n",
    "count_tot=0.0\n",
    "deviation=0.0\n",
    "for old_class in outer_loop:\n",
    "    def f(x):\n",
    "        return x[0]*np.sum(np.absolute(x[1:]))+eval_fn(X_curr+x[1:].reshape(1,1,rd),y_curr)\n",
    "    X_curr=np.copy(X_train_dr[old_class].reshape(1,1,rd))\n",
    "    X_curr_flat=X_curr.flatten()\n",
    "    y_old=np.copy(y_train[old_class].reshape((1,)))\n",
    "    print (\"Actual class is {}\".format(y_old))\n",
    "    upper_limit=np.ones(rd)-X_curr_flat\n",
    "    lower_limit=np.zeros(rd)-X_curr_flat\n",
    "    bound=zip(lower_limit,upper_limit)\n",
    "    bound.insert(0,(0,None))\n",
    "    inner_loop=np.random.randint(0,10000,10)\n",
    "    for i in inner_loop:\n",
    "        y_curr=np.copy(y_train[i].reshape((1,)))\n",
    "        if y_curr==y_old:\n",
    "            continue\n",
    "        #print (\"Target class is {}\".format(y_curr))\n",
    "        x_0=np.zeros(rd+1)\n",
    "        r,fval,info=scipy.optimize.fmin_l_bfgs_b(f,x_0,approx_grad=1,bounds=bound)\n",
    "        #r_mat=r[1:].reshape((28,28))\n",
    "        #loss_actual_ini=eval_fn(X_curr,y_old)\n",
    "        #loss_induced_ini=eval_fn(X_curr,y_curr)\n",
    "        #loss_induced_final=eval_fn(X_curr+r[1:].reshape((1,1,28,28)),y_curr)\n",
    "        #loss_actual_ini=eval_fn(X_curr+r[1:].reshape((1,1,28,28)),y_old)\n",
    "        prediction_curr=predict_fn(X_curr+r[1:].reshape((1,1,rd)))\n",
    "        if prediction_curr!=predict_fn(X_curr):\n",
    "            count_wrong=count_wrong+1\n",
    "            deviation=deviation+np.sqrt(np.sum(r[1:]**2)/rd)\n",
    "        #modified_image=(X_curr+r[1:].reshape((1,1,28,28))).reshape((28,28))\n",
    "        label_array=np.concatenate((y_old,y_curr,prediction_curr, old_class.reshape((1,)),i.reshape((1,))))\n",
    "        count_tot=count_tot+1\n",
    "if count_wrong!=0:\n",
    "    avg_deviation=deviation/count_wrong\n",
    "else:\n",
    "    avg_deviation=deviation/count_tot\n",
    "print (\"% of misclassified examples is {}\".format(count_wrong/count_tot*100))\n",
    "print (\"Deviation is {}\".format(avg_deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
